{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6692e63c",
   "metadata": {},
   "source": [
    "# Anfrageausführung\n",
    "\n",
    "\n",
    "Zoom in die interne Ebene: Die 5-Schichten Architektur\n",
    "\n",
    "<br><br>\n",
    "\n",
    "Ablauf der Anfragebearbeitung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e106be4",
   "metadata": {},
   "source": [
    "## Physische Operatoren\n",
    "\n",
    "- Anfragepläne bestehen aus Operatoren.\n",
    "    - Oft Operatoren der Relationalen Algebra (RA)\n",
    "    - Aber auch: Scan einer Tabelle\n",
    "- Physische Operatoren implementieren einen logischen Operator\n",
    "    - Oft mehrere Implementierungen pro Operator\n",
    "    \n",
    "### Tabellen Scannen\n",
    "- Einfachste Operation\n",
    "- Gesamte Relation einlesen\n",
    "    - Join, Union, …\n",
    "- Gegebenenfalls kombiniert mit Selektionsbedingung\n",
    "- Zwei Varianten\n",
    "    - Table-scan: Blöcke liegen in einer (bekannten) Region der Festplatte.\n",
    "        - Einlesen aller Blöcke\n",
    "        - Index-scan: Index besagt, welche Blöcke zur Relation gehören und wo diese liegen.\n",
    "        - Hier Kombination mit Selektionen besonders effizient (-> später)\n",
    "\n",
    "### Sortiertes Einlesen\n",
    "- Sortiertes Einlesen von Relationen kann nützlich sein:\n",
    "- 1. ORDER BY in der Anfrage\n",
    "- 2. Spätere Operatoren nutzen Sortierung aus\n",
    "- Sort-scan:\n",
    "    - Gegeben Sortierschlüssel (ein oder mehr Attribute + Sortierreihenfolge)\n",
    "    - Gegeben Relation\n",
    "    - Gebe gesamte Relation sortiert zurück\n",
    "- Implementierungsvarianten\n",
    "    - B-Baum mit Sortierschlüssel als Suchschlüssel\n",
    "    - Sequentielle Datei, sortiert nach Sortierschlüssel\n",
    "    - Relation ist klein und kann im Hauptspeicher sortiert werden\n",
    "        - Table-scan + Sortierung\n",
    "        - Index-scan + Sortierung\n",
    "    - Relation ist groß: TPMMS\n",
    "        - Ausgabe nicht auf Festplatte sondern als Iterator im Ausführungsplan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719fd7c7",
   "metadata": {},
   "source": [
    "### Berechnungsmodell\n",
    "- Kosten eines Operators\n",
    "    - Nur I/O-Kosten werden gezählt\n",
    "    - CPU-Kosten werden von I/O-Kosten dominiert\n",
    "    - Ausnahme: Netzwerkübertragung -> nicht hier\n",
    "- Annahme\n",
    "    - Input eines Operators wird von Disk gelesen\n",
    "- Output eines Operators muss nicht auf Disk geschrieben werden.\n",
    "    - Falls letzter Operator im Baum:\n",
    "        - Anwendung verarbeitet Tupel einzeln\n",
    "        - Diese I/O Kosten hängen von Anfrage ab, sowieso nicht vom Plan\n",
    "    - Falls innerer Operator:\n",
    "        - Pipelining möglich\n",
    "        \n",
    "### Kostenparameter / Statistiken\n",
    "- Verfügbarer Hauptspeicher für einen Operator: M Einheiten\n",
    "    - Eine Einheit entspricht Blockgröße auf Festplatte\n",
    "    - Hauptspeicherverbrauch nur für Input und Operator, nicht für Output\n",
    "    - Kann dynamisch (während Anfragebearbeitung) bestimmt werden\n",
    "- Deswegen: M ist nur Schätzung\n",
    "    - -> Gesamtkosten sind nur geschätzt\n",
    "    - -> Gewählter Plan nicht unbedingt optimal\n",
    "        - Dies hat auch andere Gründe. Welche?\n",
    "\n",
    "- Anzahl Blocks: B\n",
    "    - Anzahl benötigter Blocks einer Relation: B(R)\n",
    "    - Annahme: B(R) = Anzahl tatsächlich belegter Blocks\n",
    "- Anzahl Tupel: T\n",
    "    - Anzahl Tupel einer Relation: T(R)\n",
    "    - T/B = Anzahl Tupel pro Block\n",
    "- Anzahl unterschiedlicher Werte: V\n",
    "    - Anzahl unterschiedlicher Werte einer Relation R im Attribut a: V(R,a)\n",
    "    - DISTINCT values\n",
    "    - $V(R, [a1,a2,…,an]) = |\\delta(\\sigma_{a1,a2,…,an}(R))|$\n",
    "    \n",
    "**Scan-Kosten Beispiele**\n",
    "\n",
    "- R clustered\n",
    "    - Table-scan: Kosten B(R)\n",
    "    - Sort-scan\n",
    "        - Kosten B falls R in Hauptspeicher passt\n",
    "        - Kosten 3B, falls TPMMS nötig\n",
    "- R nicht clustered (also verteilt und gemischt mit Tupeln anderer Relationen)\n",
    "    - Table-Scan: Kosten T(R)\n",
    "    - Sort-scan\n",
    "        - Kosten T falls R in Hauptspeicher passt\n",
    "        - Kosten T + 2B falls TPMMS nötig\n",
    "- Index-scan\n",
    "    - Annahme: Kosten B bzw. T, auch wenn Index selbst einige Blöcke groß ist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427bf6cc",
   "metadata": {},
   "source": [
    "### Iteratoren \n",
    "-Viele physische Operatoren werden als Iterator implementiert.\n",
    "- Open()\n",
    "    - Öffnet Iterator, initialisiert Datenstrukturen\n",
    "    - Ruft wiederum Open für Input-Operator(en) auf\n",
    "    - Holt noch kein Tupel\n",
    "- GetNext()\n",
    "    - Holt nächstes Tupel\n",
    "    - Ruft wiederum GetNext für Input-Operator(en) auf\n",
    "    - Falls kein Tupel mehr vorhanden: NotFound\n",
    "- Close()\n",
    "    - Beendet und schließt Iterator\n",
    "    - Ruft wiederum Close für Input-Operator(en) auf\n",
    "    \n",
    "    \n",
    "**Pull-basierte Anfrageauswertung**\n",
    "\n",
    "**Iterator – Beispiel**\n",
    "\n",
    "**Pipelining vs. Pipeline-Breaker**\n",
    "\n",
    "**Pipelining versus Blocking**\n",
    "\n",
    "- Pipelining ist im allgemeinen sehr vorteilhaft.\n",
    "    - Kein Puffern großer Zwischenergebnisse auf Festplatte\n",
    "    - Operationen können auf Threads und CPUs verteilt werden\n",
    "- Pipeline breaker\n",
    "    - Sortierung:\n",
    "        - next() kann erst ausgeführt werden wenn gesamte Relation gesehen wurde.\n",
    "        - Ausnahme: Input ist bereits sortiert\n",
    "    - Gruppierung und Aggregation\n",
    "        - Implementiert durch Sortierung oder Hashing\n",
    "        - Dann führt next() die Aggregation für eine Gruppe aus\n",
    "    - Minus, Schnittmenge\n",
    "- Union und Projektion mit Duplikateliminierung\n",
    "    - Nicht unbedingt pipeline breaker\n",
    "    - next() kann früh Ergebnisse weiterreichen (Sortierung nicht nötig)\n",
    "    - Aber: Man muss sich alle bereits gelieferten Ergebnisse merken (großer Zwischenspeicher)\n",
    "    \n",
    "**Iterator – Beispiele**\n",
    "\n",
    "**Überblick über das Weitere**\n",
    "- Drei Klassen von Algorithmen\n",
    "    - Sort-basierte, Hash-basierte und Index-basierte Algorithmen\n",
    "- Drei Schwierigkeitsgrade von Algorithmen\n",
    "    - One-Pass Algorithmen\n",
    "        - Daten nur einmal von Disk lesen\n",
    "        - Mindestens ein Argument passt in Hauptspeicher (außer Selektion und Projektion)\n",
    "    - Two-Pass Algorithmen\n",
    "        - Meist einmal lesen, einmal schreiben, nochmal lesen\n",
    "        - TPMMS\n",
    "        - Gewisse Größenbeschränkung auf Input\n",
    "    - Multipass Algorithmen\n",
    "        - Unbeschränkt in Inputgröße\n",
    "        - Rekursive Erweiterungen von Two-Pass Algorithmen\n",
    "    - U.a. abhängig vom Operator\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9658f381",
   "metadata": {},
   "source": [
    "## One-Pass Algorithmen\n",
    "\n",
    "### Operatorklassen für One-pass Verfahren\n",
    "\n",
    "- Tupel-basierte unäre Operatoren\n",
    "    - Benötigen jeweils nur sehr kleinen Teil des Input gleichzeitig im Hauptspeicher\n",
    "    - Projektion, Selektion, (Multimengen-Vereinigung)\n",
    "- Relationen-basierte unäre Operatoren\n",
    "    - Benötigen gesamte Relation im Hauptspeicher\n",
    "    - Deshalb Beschränkung der Inputgröße auf Hauptspeichergröße\n",
    "    - Gruppierung, Duplikateliminierung, Sortierung\n",
    "- Relationen-basierte binäre Operatoren\n",
    "    - Benötigen mindestens eine gesamte Relation im Hauptspeicher (falls sie one-pass sein sollen)\n",
    "    - Alle Mengenoperatoren (außer Multimengen-Vereinigung)\n",
    "    - Join\n",
    "    \n",
    "### Tupel-basierte unäre Operatoren\n",
    "\n",
    "- Algorithmus für Selektion und Projektion offensichtlich\n",
    "    - Unabhängig von Hauptspeichergröße\n",
    "- Speicherkosten: 1\n",
    "- I/O Kosten: Wie table-scan oder index-scan\n",
    "    - B, falls geclustert\n",
    "    - T, falls nicht geclustert\n",
    "    - Weniger, falls Selektion auf Suchschlüssel eines Index\n",
    "- Puffer > 1 nützlich. Wieso?\n",
    "    - „Daten gemäß Zylinder organisieren“\n",
    "    - Alle Blocks eines Zylinders gleichzeitig lesen.\n",
    "    \n",
    "### Relationen-basierte unäre Operatoren\n",
    "\n",
    "- Operatoren: Duplikateliminierung und Gruppierung\n",
    "    - Ganze Relation muss in den Hauptspeicher passen\n",
    "- Genereller „Trick“: Bewahre nur „Repräsentanten“ im Hauptspeicher\n",
    "    - Duplikateliminierung: Eindeutige Repräsentation schon gesehener Tupel\n",
    "    - Gruppierung: Gruppierungsattribute und aggregierte Teilergebnisse\n",
    "    - Dadurch können auch größere Relationen verarbeitet werden.\n",
    "    \n",
    "### Duplikateliminierung\n",
    "\n",
    "- Tupel für Tupel einlesen\n",
    "    - Erstes Mal dieses Tupel gesehen -> Ausgabe\n",
    "    - Schon mal gesehen -> nix tun\n",
    "- Puffer merkt sich welche Tupel bereits gesehen wurden\n",
    "    - Datenstruktur wichtig (trotz I/O Dominanz)\n",
    "        - Einfügen eines Tupels und Finden eines Tupels in fast konstanter Zeit\n",
    "        - Z.B. Hashtabelle, balancierter Binärbaum\n",
    "        - Geringer Speicher-overhead\n",
    "- Wahl von M: $B(\\delta(R)) = V(R, [A1, … ,An])$ / Tupel-pro-Block ≤ M\n",
    "\n",
    "### Gruppierung\n",
    "\n",
    "- Idee: Erzeuge im Hauptspeicher einen Eintrag pro Gruppe\n",
    "- Also ein Eintrag pro Gruppierungswert\n",
    "- Dazu: Kumulierte Werte für aggregierte Attribute\n",
    "    - Einfach: MIN/MAX, COUNT, SUM\n",
    "    - Schwerer: AVG (Warum?)\n",
    "        - AVG ist nicht assoziativ.\n",
    "        - Merke COUNT und SUM\n",
    "        - AVG erst am Ende berechnen\n",
    "- Wieder: Datenstruktur im Hauptspeicher ist wichtig.\n",
    "- Output: Ein Tupel pro Eintrag\n",
    "    - Output erst nachdem letzter Input gesehen wurde (Blockierend)\n",
    "- Hautspeicherkosten: Schwer abzuschätzen\n",
    "    - Einträge selbst können größer oder kleiner als Tupel sein\n",
    "    - Anzahl der Einträge höchstens so groß wie T\n",
    "    - Meistens M << B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff678bdb",
   "metadata": {},
   "source": [
    "### Relationen-basierte binäre Operatoren\n",
    "\n",
    "- Vereinigung, Schnittmenge, Differenz, Kreuzprodukt, Join\n",
    "    - Außer $\\cup_{B}$\n",
    "    \n",
    "    \n",
    "- Annahme: Eine Inputmenge passt in Hauptspeicher\n",
    "    - Wieder: Effiziente Datenstruktur sinnvoll\n",
    "    - Hauptspeicherbedarf: M ≥ min(B(R), B(S))\n",
    "        - Hier: B(S) < B(R)\n",
    "        \n",
    "        \n",
    "- Unterscheidung: Multimengensemantik (z.B. $\\cup_{B}$) vs. Mengensemantik ($\\cup_{S}$)\n",
    "\n",
    "- R $\\cup_{B}$ S trivial\n",
    "    - I/O-Kosten: B(R) + B(S)\n",
    "    - Hauptspeicherbedarf: 1\n",
    "    \n",
    "    \n",
    "- R  $\\cup_{S}$ S\n",
    "    - Lese alle Tupel aus S und baue Datenstruktur auf\n",
    "        - Schlüssel ist gesamtes Tupel\n",
    "    - Gebe alle diese Tupel aus\n",
    "    - Lese R ein\n",
    "        - Falls schon vorhanden: Nix tun\n",
    "        - Fall nicht: Ausgeben (Falls R Duplikate enthält muss man im schlimmsten Fall auch R in Speicher halten)\n",
    "- R $\\cap_{S}$ S\n",
    "    - Lese alle Tupel aus S und baue Datenstruktur auf\n",
    "        - Schlüssel ist gesamtes Tupel\n",
    "        - Noch keine Tupel ausgeben\n",
    "    - Lese R ein\n",
    "        - Falls vorhanden: Ausgabe\n",
    "        - Falls nicht vorhanden: Nix tun\n",
    "    - Annahme: R und S sind Mengen\n",
    "    \n",
    "    \n",
    "- Mengen-Differenz\n",
    "    - Nicht kommutativ!\n",
    "    - Annahmen\n",
    "        - R und S sind Mengen\n",
    "        - S ist kleiner als R\n",
    "        \n",
    "        \n",
    "- Zunächst immer: Lese S in effiziente Datenstruktur ein\n",
    "    - Gesamtes Tupel ist Schlüssel\n",
    "    \n",
    "    \n",
    "- R $-_{S}$ S\n",
    "    - Lese R ein\n",
    "        - Falls Tupel schon vorhanden: Nix tun\n",
    "        - Falls nicht vorhanden: Ausgabe\n",
    "        \n",
    "        \n",
    "- S $-_{S}$ R\n",
    "    - Lese R ein\n",
    "        - Falls Tupel schon vorhanden: Lösche aus Datenstruktur\n",
    "        - Falls nicht vorhanden: Nix tun\n",
    "    - Gebe übrig gebliebenen Tupel aus.\n",
    "    \n",
    "    \n",
    "- R $\\cap_{B}$ S\n",
    "    - Lese S ein\n",
    "        - Merke einen COUNT-Wert pro Tupel\n",
    "    - Lese R ein\n",
    "        - Falls nicht bereits vorhanden: Nix tun\n",
    "        - Falls vorhanden und COUNT > 0: Ausgabe und COUNT reduzieren\n",
    "        - Sonst: Nix tun\n",
    "        \n",
    "        \n",
    "- Multimengendifferenz\n",
    "    - S -B R\n",
    "        - Lese S ein und speichere einen COUNT-Wert\n",
    "        - Lese R ein\n",
    "            - Falls Tupel schon vorhanden: Verringere COUNT\n",
    "            - Falls nicht vorhanden: Nix tun\n",
    "        - Gebe Tupel mit COUNT > 0 entsprechend oft aus.\n",
    "        \n",
    "    - R -B S\n",
    "        - Lese S ein und speichere einen COUNT-Wert (c)\n",
    "            - c Gründe ein Tupel aus R nicht auszugeben\n",
    "    - Lese R ein\n",
    "        - Falls Tupel schon vorhanden und COUNT > 0: COUNT verringern\n",
    "        - Falls Tupel schon vorhanden und COUNT = 0: Ausgabe\n",
    "        - Falls nicht vorhanden: Ausgabe\n",
    "        \n",
    "- R x S\n",
    "    - Lese S in Hauptspeicher ein\n",
    "        - Datenstruktur egal\n",
    "    - Lese R ein\n",
    "        - Konkateniere mit jedem Tupel aus S\n",
    "        - Ausgabe\n",
    "    - Rechenzeit pro Tupel lang: Ausgabe ist eben groß\n",
    "- R(X,Y) ⋈ S(Y,Z) (natural join)\n",
    "    - Lese S in Hauptspeicher ein: Y als Suchschlüssel\n",
    "    - Lese R ein\n",
    "        - Für jedes Tupel, suche passende Tupel aus S und gebe aus\n",
    "    - I/O Kosten: B(S) + B(R)\n",
    "    - Annahme: B(S) ≤ M-1 bzw. vereinfacht: B(S) ≤ M\n",
    "    - Equi-join analog\n",
    "    - Theta-join: analog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9e34d1",
   "metadata": {},
   "source": [
    "## Nested Loop Join\n",
    "\n",
    "- 1.5-pass Algorithmen\n",
    "    - Eine Relation nur einmal einlesen\n",
    "    - Die andere Relation mehrfach einlesen\n",
    "- Größe beider Relationen beliebig\n",
    "- Tupel-basierte Variante – Naïv\n",
    "\n",
    "```\n",
    "FOR EACH TUPLE s IN S DO\n",
    "    FOR EACH TUPLE r IN R DO\n",
    "    IF (r.Y = s.Y) THEN OUTPUT (r ⋈ s)\n",
    "```\n",
    "\n",
    "- I/O-Kosten: T(S) + T(S) · T(R)\n",
    "- Verbesserungen\n",
    "    - Index auf Joinattribut in R (später)\n",
    "    - Aufteilung der Tupel auf Blöcke berücksichtigen (gleich)\n",
    "    \n",
    "### Block-basierter NLJ\n",
    "\n",
    "- Ideen\n",
    "    - Organisiere Tupel nach Blöcken\n",
    "        - Sinnvoll für innere Schleife\n",
    "    - Nutze Hauptspeicher\n",
    "        - So viel wie möglich von S (äußere Schleife) halten\n",
    "        - -> Ein R-Tupel wird nicht nur mit einem, sondern mit vielen S-Tupeln verjoint.\n",
    "    - Hinweise\n",
    "        - Empfehlung: B(S) ≤ B(R) (wie bisher)\n",
    "        - B(S) > M (schwieriger als bisher in 1-pass)\n",
    "        - Effiziente Datenstruktur für S im Hauptspeicher\n",
    "     \n",
    "     \n",
    "        \n",
    "```\n",
    "FOR EACH chunk of M-1 blocks of S DO BEGIN\n",
    "read blocks into main memory;\n",
    "organize tuples into efficient data structure;\n",
    "FOR EACH block b of R DO BEGIN\n",
    "read b into main memory;\n",
    "FOR EACH tuple t of b DO BEGIN\n",
    "find tuples of S in main memory that join;\n",
    "output those joined tuples;\n",
    "END;\n",
    "END;\n",
    "END;\n",
    "```\n",
    "\n",
    "Eigentlich: M – 2 wg. Outputbuffer\n",
    "<br><br>\n",
    "Drei Schleifen?\n",
    "<br><br>\n",
    "\n",
    "\n",
    "**Block-basierter NLJ – Kosten**\n",
    "\n",
    "- B(R) = 1.000\n",
    "- B(S) = 500\n",
    "- M = 101\n",
    "- -> 5x äußere Schleife á 100 I/O\n",
    "- -> jeweils 1.000 I/O für R\n",
    "- = 5.500 I/O\n",
    "- Nun: R in äußerer Schleife\n",
    "    - -> 10x äußere Schleife á 100 I/O\n",
    "    - -> jeweils 500 I/O für S\n",
    "    - = 6.000 I/O\n",
    "- -> Kleinere Relation sollte außen sein.\n",
    "\n",
    "\n",
    "- B(S) = 100\n",
    "- B(R) = 1.000.000\n",
    "- Extremfall 1 (R außen)\n",
    "- 10.000x äußere Schleife á (100 + 100 I/O)\n",
    "- = 10.000 x 200 = 2.000.000 I/O\n",
    "- Extremfall 2 (S außen)\n",
    "- 1x äußere Schleife á (100 + 1.000.000 I/O)\n",
    "- = 1x 1.000.100 I/O\n",
    "\n",
    "\n",
    "- Allgemeinere Berechnung\n",
    "-  Äußere Schleife: B(S)/(M − 1)-fach\n",
    "- Jeweils\n",
    "    - M−1 Blöcke von S\n",
    "    - B(R) Blöcke von R\n",
    "- Zusammen\n",
    "\n",
    "- $\\frac{B(S)}{M-1}(M-1+B(R)) = \\frac{B(S)(M-1)}{M-1} - \\frac{B(S)}{M-1} + \\frac{B(S)B(R)}{M-1} \\approx B(S)B(R)/M$\n",
    "\n",
    "### Zusammenfassung bisheriger Algorithmen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d5d86f",
   "metadata": {},
   "source": [
    "## Sort-basierte Two-Pass Algorithmen\n",
    "\n",
    "**1-, 2-, Mehr-Phasen**\n",
    "\n",
    "- Bisher: One-Pass Algorithmen; eine Relation passt in Hauptspeicher\n",
    "- Nun: Two-Pass Algorithmen; keine Relation passt in Hauptspeicher\n",
    "- Zwei Phasen\n",
    "    - Einlesen der Daten\n",
    "    - Verarbeitung der Daten (hier: Sortierung von Teillisten)\n",
    "    - Schreiben der Daten\n",
    "    - Wiedereinlesen der Daten (hier: Merging der Teillisten)\n",
    "        - Hier unterscheiden sich die Algorithmen\n",
    "- Mehr-Phasen?\n",
    "    - Zwei Phasen reichen meist\n",
    "    - Verallgemeinerung zu Mehr-Phasen einfach\n",
    "    \n",
    "### Duplikateliminierung\n",
    "\n",
    "- Idee: Ähnlich wie TPMMS\n",
    "- Phase 1 wie bisher\n",
    "    - Sortierschlüssel ist gesamtes Tupel\n",
    "- Phase 2: Ein Block pro sortierter Teilliste\n",
    "    - Betrachte jeweils erstes Tupel\n",
    "    - Suche kleinstes Tupel\n",
    "    - Gib dieses Tupel aus; verwerfe alle anderen identischen Tupel\n",
    "- Beispiel\n",
    "    - M = 3 + 1; 2 Tupel pro Block\n",
    "    - 17 Tupel: 2, 5, 2, 1, 2, 2, 4, 5, 4, 3, 4, 2, 1, 5, 2, 1, 3\n",
    "    - Phase 1: 3 sortierte Teillisten\n",
    "    - Phase 2: s.o.\n",
    "- Verbesserung schon in Phase 1?\n",
    "    - Duplikateliminierung in Teillisten -> Kleinere Teillisten\n",
    "    \n",
    "**Duplikateliminierung Kosten**\n",
    "\n",
    "- Wie TPMMS\n",
    "1. B(R) für Einlesen in Phase 1\n",
    "2. B(R) für Schreiben der Teillisten\n",
    "3. B(R) für Lesen der Teillisten\n",
    "    - Zusammen: 3·B(R)\n",
    "- One-pass Algorithmus: 1·B(R)\n",
    "- Aber hier größerer Input möglich\n",
    "    - One-pass: B ≤ M\n",
    "    - Two-pass: B ≤ M²\n",
    "    \n",
    "### Gruppierung und Aggregation\n",
    "\n",
    "- Phase 1\n",
    "1. Lese R ein (jeweils M Blöcke)\n",
    "2. Sortiere M Blöcke nach Gruppierungsattribut(en)\n",
    "3. Schreibe sortierte Teillisten\n",
    "- Phase 2\n",
    "1. Lade jeweils einen Block jeder Teilliste\n",
    "2. Suche kleinste Schlüssel (neue Gruppe)\n",
    "3. Aggregiere alle Tupel mit diesem Schlüssel\n",
    "    - Gegebenenfalls Blöcke nachladen\n",
    "4. Gebe ein Tupel mit aggregierten Werten (und gegebenenfalls Gruppierungsattribut) aus.\n",
    "5. Suche nächst kleineren Schlüssel\n",
    "- I/O-Kosten: 3B(R) Maximale Größe: B(R) ≤ M²\n",
    "- Verbesserung Phase 1: Aggregation schon auf Teillisten\n",
    "    - „Pre-Aggregation“: Besonders wichtig für verteilte DBMS\n",
    "    \n",
    "    \n",
    "### Vereinigung (binär)\n",
    "\n",
    "1. Lese R ein und schreibe sortierte Teillisten\n",
    "    - Sortierschlüssel ist gesamtes Tupel\n",
    "2. Lese S ein und schreibe sortierte Teillisten\n",
    "    - Sortierschlüssel ist gesamtes Tupel\n",
    "3. Lese jeweils einen Block aus beiden Mengen sortierter Teillisten\n",
    "4. Suche kleinste Tupel aus allen Blöcken\n",
    "    - -> Ausgabe\n",
    "    - Entfernung aus allen anderen Teillisten\n",
    "        - Zur Not: Blöcke nachladen\n",
    "5. Suche nächstes kleinstes Tupel\n",
    "- Funktioniert für Mengen und Multimengen\n",
    "    - Bei Multimengen ist one-pass Algorithmus besser\n",
    "- I/O-Kosten: 3(B(R) + B(S))\n",
    "- Maximale Größe: B(R) + B(S) ≤ M²\n",
    "\n",
    "### Schnittmenge und Differenz\n",
    "\n",
    "1. Sortierung und Laden der Teillisten wie bei Vereinigung\n",
    "2. Suche kleinstes Tupel t\n",
    "3. Zählen\n",
    "    - count(R, t) = Anzahl der Vorkommen von t in R\n",
    "    - count(S, t) analog\n",
    "    - Gegebenenfalls nachladen\n",
    "4. Ausgabe je nach Operator\n",
    "    - $\\cap_{S}$: Ausgabe von t falls count(R, t) > 0 und count(S, t)>0\n",
    "    - $\\cap_{B}$gebenenfalls nicht ausgeben (wenn ein count = 0)\n",
    "    - $R-_{S}S$: Ausgabe von t falls count(R, t) > 0 und count(S, t) = 0\n",
    "    - $R-_{B}S$: Ausgabe von t max[0, count(R, t) -count(S, t)] mal\n",
    "5. Suche nächstes kleinstes Tupel t …\n",
    "- I/O-Kosten: 3(B(R) + B(S))\n",
    "- Maximale Größe: B(R) + B(S) ≤ M²"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde62785",
   "metadata": {},
   "source": [
    "### Einfacher, Sort-basierter Join Algorithmus\n",
    "\n",
    "- Neues Problem bei Join: Alle Tupel mit gleichem Joinattributwert müssen gleichzeitig im Hauptspeicher sein.\n",
    "- Lösungsidee: Reserviere so viel Speicher wie möglich für aktuelle Jointupel\n",
    "    - Reduziere Speicherbedarf anderer Algorithmusteile\n",
    "- R(X, Y) ⋈ S(Y, Z)\n",
    "- Phase 1: Sortiere R und S jeweils gemäß Y mit TPMMS\n",
    "    - Inkl. letzter Phase (Schreiben des sortierten Ergebnisses)\n",
    "- Phase 2: Merge R und S\n",
    "1. Jeweils ein Block\n",
    "2. Suche insgesamt kleinstes Y in beiden Blocks\n",
    "3. Falls nicht in anderem Block vorhanden: Entferne alle Tupel mit diesem Y\n",
    "4. Falls vorhanden: Identifiziere alle Tupel mit diesem Y \n",
    "    - – Gegebenenfalls nachladen\n",
    "5. Gebe alle Kombinationen aus\n",
    "\n",
    "**Kosten**\n",
    "\n",
    "- R: 1000 Blocks; S: 500 Blocks; M = 101\n",
    "- TPMMS: 4·B(R) + 4·B(S) = 4·1500 = 6000 I/O\n",
    "- Merging: Nochmals R und S lesen: 1500 I/O\n",
    "    - Nur 2 Blocks werden benötigt\n",
    "    - Aber: Alle Tupel mit einem bestimmten Y-Wert müssen in 98 Blöcke passen\n",
    "- I/O: 5(B(R) + B(S)) = 7500 I/O\n",
    "- Hauptspeicher: B(R)≤M² und B(S)≤M²\n",
    "- Vergleich zu nested loops: 5500 I/O\n",
    "    - Aber nested loops ist quadratisch: B(R)B(S)/M\n",
    "    - Sort-based join ist linear\n",
    "    - Gleich noch Verbesserung auf 3(B(R) + B(S)) \n",
    "    \n",
    "**Erweiterung**\n",
    "- Falls alle Tupel (beider Relationen) mit einem bestimmten Y-Wert nicht in Hauptspeicher passen\n",
    "    - Falls alle solche Tupel einer Relation in M−1 Blöcke passen\n",
    "        - One-pass join für diesen Y-Wert\n",
    "    - Falls nicht: Nested loop join\n",
    "- Fallunterscheidung kann überflüssiges I/O vermeiden.\n",
    "- Diskussion\n",
    "    - Y ist oft in einer Relation ein Schlüssel => leicht\n",
    "    \n",
    "**Verbesserung des Sort-basierter Join Algorithmus**\n",
    "- Idee: Kombiniere 2te Phase des TPMMS mit dem Joinen\n",
    "    - => („sort-join“, „merge-join“) „sort-merge-join“\n",
    "1. Erzeuge sortierte Teillisten der Größe M jeweils für R und S mit Y als Sortierschlüssel\n",
    "2. Lade erste Blöcke aller Teillisten (beider Relationen)\n",
    "3. Suche kleinste Y-Werte und erzeuge Jointupel\n",
    "- Annahmen\n",
    "    - Anzahl aller Teillisten (aus R und S) ≤ M\n",
    "    - Tupel mit gemeinsamen Y-Werten passen zusammen in verbleibenden Hauptspeicher\n",
    "- R: 1000 Blocks; S: 500 Blocks; M = 101\n",
    "    - Phase 1: 10 Teillisten für R, 5 Teillisten für S\n",
    "    - Phase 2: 15 Blöcke gleichzeitig im Hauptspeicher\n",
    "        - => 86 freie Blöcke für aktuelle Join-Tupel\n",
    "    - Zusammen 3(B(R) + B(S)) = 4500 I/O\n",
    "- Oft sind viele Speicherblöcke übrig, da B(R)+B(S) << M²\n",
    "\n",
    "### Zusammenfassung – sortbasierte, two-pass Algorithmen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a72af2a",
   "metadata": {},
   "source": [
    "## Hash-basierte Two-Pass Algorithmen\n",
    "\n",
    "- Input passt nicht in Hauptspeicher (wie immer).\n",
    "- Hashe alle Inputargumente.\n",
    "    - Tupel, die gemeinsam betrachtet werden müssen, erhalten gleichen Hashwert.\n",
    "    - Landen also in einem Bucket\n",
    "- Unäre Operatoren: Bearbeite anschließend einen Bucket nach dem anderen\n",
    "- Binäre Operatoren: Bearbeite anschließend Paare von Buckets\n",
    "- Oft: Mehr als ein Block pro Bucket\n",
    "- Allgemein: Reduktion des Speicherbedarfs um Faktor M im Vergleich zu Größe der Relationen\n",
    "    - Verwende ≤M Buckets\n",
    "    - Jeder einzelne Bucket muss in Hauptspeicher passen.\n",
    "    \n",
    "### Partitionierung mittels Hashing\n",
    "\n",
    "- Grundalgorithmus\n",
    "- Gegeben M Speicherblöcke, verteile R auf M−1 Buckets\n",
    "    - Möglichst gleicher Größe\n",
    "    - Ein Bucket pro Speicherblock\n",
    "- Letzter Speicherblock für Einlesen der Tupel aus R\n",
    "- Idee\n",
    "    - Für jedes Tupel aus R berechne h(t) und bewege Tupel in entsprechenden Bucket.\n",
    "    - Falls Block voll: Schreibe als Overflowblock auf Disk\n",
    "    - Am Ende: Schreibe auch alle Buckets auf Disk\n",
    "\n",
    "```\n",
    "initialize M-1 buckets using M-1 empty buffers;\n",
    "FOR each block b of R DO BEGIN\n",
    "    read block b into M-th buffer\n",
    "    FOR each tuple t in b DO BEGIN\n",
    "        IF buffer for bucket h(t) has no room for t THEN\n",
    "            BEGIN\n",
    "                copy the buffer to disk; /* spill */\n",
    "                initialize a new empty block in that buffer;\n",
    "            END;\n",
    "        copy t to buffer for bucket h(t);\n",
    "    END;\n",
    "END;\n",
    "FOR each bucket DO\n",
    "    IF the buffer for this bucket is not empty THEN\n",
    "        write the buffer to disk;\n",
    "        \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f445201a",
   "metadata": {},
   "source": [
    "### Duplikateliminierung $\\delta(R)$\n",
    "\n",
    "- Algorithmus wie eben:\n",
    "    - Ganzes Tupel als Hash-Input (ist das nötig?)\n",
    "- Duplikate landen im gleichen Bucket.\n",
    "- Betrachte jeden Bucket einzeln.\n",
    "    - Duplikateliminierung innerhalb des Buckets\n",
    "    - Danach Bucket ausgeben\n",
    "- Annahme: Alle Blöcke eines Buckets passen in Hauptspeicher\n",
    "    - => One-pass Algorithmus funktioniert pro Bucket\n",
    "    - Bei Gleichverteilung durch h: Bucket hat B(R)/(M−1) Blöcke\n",
    "    - => R darf bis zu M(M−1) viele Blöcke umfassen\n",
    "    - Vermutlich noch besser (wie zuvor): Es müssen nur distinct Tupel in Hauptspeicher passen\n",
    "- I/O-Kosten: 3·B(R)\n",
    "\n",
    "### Gruppierung und Aggregation $\\gamma_{L}(R)$\n",
    "- Grundalgorithmus wie zuvor\n",
    "- Aber: Hashfunktion hängt nur von Gruppierungsattributen ab.\n",
    "    - Problem oft: Nur wenig verschiedene Werte (z.B. Bundesland)\n",
    "    - => nur wenige (und damit große) Buckets\n",
    "- Dann: One-pass Algorithmus für Gruppierung auf jedem Bucket\n",
    "- Hauptspeicherbedarf: B(R) ≤ M²\n",
    "    - Vermutlich viel geringer: Nur ein Tupel pro Gruppe/Bucket im Hauptspeicher\n",
    "- I/O-Kosten: 3·B(R)\n",
    "\n",
    "### Mengenoperationen\n",
    "\n",
    "- Bei binären Operationen: Gleiche Hashfunktion für beide Inputs!\n",
    "- Mengenvereinigung:\n",
    "    - Hashe R und S jeweils auf M−1 Buckets\n",
    "    - Bilde Mengenvereinigung passender Bucketpaare\n",
    "- Wieder: Jeweils One-pass Algorithmus anwenden\n",
    "- Multimengenvereinigung: Voriger Algorithmus\n",
    "- Speicherbedarf: min(B(R), B(S)) ≤ (M−1)²\n",
    "    - Warum?\n",
    "    - Da bei One-pass Varianten kleinere Relation in Hauptspeicher passen muss\n",
    "- I/O-Kosten: 3·(B(R) + B(S))\n",
    "\n",
    "### Hashjoin\n",
    "\n",
    "- Algorithmus wie zuvor\n",
    "- Aber: Hashschlüssel sind Joinattribute\n",
    "    - Tupel mit gleichen Joinattributwerten landen im korrespondierenden Bucket.\n",
    "- Danach One-pass Join Variante für jedes Bucket-Paar\n",
    "- Beispiel von zuvor: B(R) = 1000, B(S) = 500, M = 101\n",
    "- Hashing\n",
    "    - Ca. 10 R-Blocks pro Bucket\n",
    "    - Ca. 5 S-Blocks pro Bucket\n",
    "- Min(10, 5) = 5 => One-pass Algorithmus klappt (5 < 101)\n",
    "    - Hole ersten S-Bucket in Hauptspeicher;\n",
    "    - Joine Blöcke des passenden R-Buckets hinzu\n",
    "    - Hole nächsten S-Bucket in Hauptspeicher … usw …\n",
    "- I/O-Kosten:\n",
    "    - 1500 für das Hashing + 1500 um Buckets zu schreiben\n",
    "    - 1500 um Buckets zu lesen\n",
    "    - Zusammen: 3(B(R) + B(S)) = 4500 (wie sort-basierte Methode)\n",
    "- Aber es geht noch besser.\n",
    "\n",
    "### I/O Einsparungen\n",
    "\n",
    "- Grundidee: Nutze nicht-verwendeten Speicher\n",
    "    - Idee 1: Verwende mehr als 1 Speicherblock pro Bucket\n",
    "        - Effizienteres Schreiben (aber gleiche I/O-Kosten)\n",
    "    - Idee 2: Hybrid Hashjoin\n",
    "        - Beim Hashen von S: Behalte m Buckets komplett im Speicher\n",
    "            - Auch nach Ende des Hashens\n",
    "            - Jeweils mit geeigneter Datenstruktur\n",
    "        - Schon in der Hash-Phase von R: Join-Tupel in den m Buckets produzieren\n",
    "            - Für alle anderen Buckets wie bisher: Join in zweiter Phase\n",
    "            \n",
    "### I/O Einsparungen – Hybrid Hashjoin\n",
    "\n",
    "- Beim Hashen von S: Behalte m Buckets komplett im Speicher.\n",
    "- Falls k Buckets insgesamt für S nötig sind: Verwende für die übrigen k – m Buckets jeweils nur einen Block im Hauptspeicher beim Hashen.\n",
    "- Es muss gelten: ( m · B(S)/k ) + 1 · (k – m) ≤ M\n",
    "    - Wähle also m entsprechend\n",
    "- Schreibe die k – m Rest-Blöcke auf Disk.\n",
    "- Beim Hashen von R sind nun im Hauptspeicher:\n",
    "    - m vollständige Buckets für S\n",
    "    - je ein Block für die k–m Buckets von R, deren korrespondierende S-Buckets auf Disk sind\n",
    "- Falls Tupel t aus R in einen der m Buckets gehasht wird:\n",
    "    - Joinpartner suchen\n",
    "    - Gegebenenfalls direkte Ausgabe\n",
    "- Falls t in einen der k–m Buckets gehasht wird\n",
    "    - Verfahre wie zuvor: Auf Disk schreiben\n",
    "- Phase 2 dann nur noch auf den k – m Buckets\n",
    "\n",
    "### Hybrid Hashjoin – Analyse\n",
    "\n",
    "- Einsparungen\n",
    "    - Spare 2 I/Os für jeden Block, der im Hauptspeicher gehalten werden kann (nämlich m/k aller Buckets)\n",
    "    - Einsparung also 2(m/k) (B(R) + B(S))\n",
    "- => Maximiere (m/k), gegeben ( m · B(S)/k ) + k – m ≤ M\n",
    "    - Lösung: Wähle m = 1 und minimiere k.\n",
    "        - Intuition: Alle Puffer bis auf k – m werden verwendet, um Tupel im Hauptspeicher zu halten; davon bitte möglichst viele.\n",
    "- Minimierung von k (gesamte Anzahl der Buckets): Wähle Bucketgröße so, dass ein Bucket gerade eben in Hauptspeicher passt.\n",
    "    - Bucketgröße M\n",
    "    - => k = B(S) / M\n",
    "        - => nur ein Bucket passt in Hauptspeicher (=> m = 1)\n",
    "    - Bucketgröße eigentlich etwas kleiner, damit die übrigen (wenigen) Buckets durch mindestens einen Block repräsentiert werden können\n",
    "- => Einsparungen 2(m/k) (B(R) + B(S)) = 2 (1/ (B(S)/M) ) · (B(R) + B(S)) = (2M / B(S)) · (B(R) + B(S))\n",
    "- => I/O-Kosten: (3 – (2M/B(S))) · (B(R) + B(S))\n",
    "\n",
    "=> Wähle wenige große Buckets statt viele kleine\n",
    "\n",
    "**Hybrid Hashjoin – Beispiel**\n",
    "\n",
    "- B(R) = 1000, B(S) = 500, M = 101\n",
    "-  Wähle z.B. k = B(S) / M = 500 / 101 ≈ 5\n",
    "    - => Ein Bucket hat ca. 100 Blocks\n",
    "    - => 104 Hauptspeicher nötig (> 101)\n",
    "        - +1 für Lesen der Relation\n",
    "    - => Besser k = 6\n",
    "- Je 1 Puffer für erste 5 Buckets +1 für Lesen der Relation und 95 Puffer für letzten Bucket\n",
    "    - Erwartete Größe: 500/6 ≈ 83\n",
    "- Phase 1\n",
    "    - I/O-Kosten für S: 500x lesen und 417x schreiben\n",
    "    - I/O-Kosten für R: 1000x lesen und 833x schreiben (5 der 6 Buckets)\n",
    "- Phase 2\n",
    "    - Alle geschriebenen Blöcke wieder lesen: 417 + 833 = 1250\n",
    "- Zusammen: 500 + 1000 + 2·(417 + 833) = 4000 I/Os\n",
    "    - < 4500 bei einfachen Hash-Join bzw. Sort merge Join!\n",
    "- Warum nur von S (und nicht von R) abhängig?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dab6ba7",
   "metadata": {},
   "source": [
    "### Zusammenfassung Hash-basierter Verfahren\n",
    "\n",
    "**Wdh.: Sort-basierte, two-pass Algorithmen**\n",
    "\n",
    "**Vergleich Hash-basierte und Sort-basierte Algorithmen**\n",
    "- Speicherbedarf und I/O-Kosten ähnlich\n",
    "- Speicherbedarf Hash-basierter Verfahren hängt nur vom kleineren der beiden Inputs statt Summe der beiden Inputs ab.\n",
    "- Sortier-basierte Verfahren produzieren oft einen sortierten Output\n",
    "    - Vorteile später im Plan\n",
    "- Sortierbasierte Verfahren können sortierte Teilliste hintereinander auf Disk schreiben\n",
    "    - Spart bei einer I/O-Operation Seektime\n",
    "    - Bei großem M: Auch mehrere Blöcke einer Liste auf einmal lesen\n",
    "- Gleiches auch bei Hash-basierten Verfahren möglich, falls Anzahl Buckets kleiner als M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd7ee63",
   "metadata": {},
   "source": [
    "## Index-basierte Algorithmen\n",
    "\n",
    "- Indizes ermöglichen manchmal andere Algorithmen.\n",
    "- Insbesondere Selektion\n",
    "- Aber auch: Joins und andere binäre Operatoren\n",
    "- Clustered Relation\n",
    "    - Tupel auf so wenig wie möglich Blöcken auf Disk\n",
    "- Clustering Index\n",
    "    - Tupel mit gleichem Schlüsselwert sind auf so wenig wie möglich Blöcken\n",
    "        - Eventuell +1 Block wegen Layout\n",
    "    - Oft: Relation ist bereits clustered und clustering index ist auf dem Primärschlüssel\n",
    "- Eine clustered Relation kann auch non-Cluster-Indizes haben.\n",
    "\n",
    "### Index-basierte Selektion\n",
    "\n",
    "- Basisalgorithmus: Lese gesamte Relation ein und prüfe Bedingung\n",
    "    - Ohne Index ist dies die beste Methode\n",
    "    - I/O-Kosten: B(R) bzw. T(R) falls R nicht clustered\n",
    "- Besser: Selektionsbedingung a=v und a ist Suchschlüssel eines Cluster-Indexes\n",
    "    - I/O-Kosten: $\\lceil B(R)/V(R,a)\\rceil$\n",
    "        - Reminder: V(R,L) = Anzahl distinct Werte von pL(R)\n",
    "    - Eventuell mehr\n",
    "        - I/O-Kosten für Index\n",
    "        - Tupel nicht perfekt auf Blöcke verteilt: 1 Block extra\n",
    "        - Blöcke nicht absolut vollgepackt\n",
    "        - Fremde Tupel auf Blöcken\n",
    "        - Aufrunden: a ist Schlüssel => V(R,a) = T(R) >> B(R)\n",
    "        - Dennoch mindestens 1 Block\n",
    "\n",
    "\n",
    "\n",
    "- Selektionsbedingung a=v und a ist Suchschlüssel eines nicht-Cluster-Indexes\n",
    "- => Jedes Tupel auf anderen Block (vermutlich)\n",
    "- I/O-Kosten: $\\lceil T(R) / V(R,a)\\rceil$\n",
    "    - Wieder zusätzliche I/O-Kosten: Indizes\n",
    "    - Etwas besser, falls zufällig mehr als ein Tupel auf dem Block\n",
    "    \n",
    "**Index-basierte Selektion – Beispiel**\n",
    "- Beispiel: B(R) = 1000, T(R) = 20000 (=> 20 Tupel pro Block)\n",
    "    - Anfrage: sa=0(R); Index auf a\n",
    "    - R ist clustered; Index wird nicht verwendet:\n",
    "        - 1000 I/Os\n",
    "    - R nicht clustered; Index wird nicht verwendet:\n",
    "        - 20000 I/Os\n",
    "    - V(R,a)=100; Index ist clustering:\n",
    "        - 1000/100 = 10 I/Os\n",
    "    - V(R,a) = 10; Index ist nicht clustering:\n",
    "        - 20000/10 = 2000 I/Os\n",
    "        - Falls R clustered: Lieber ganz R einlesen (1000 I/O)\n",
    "    - V(R,a) = 20000 (d.h. a ist Schlüssel):\n",
    "        - 1 I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59db4a5c",
   "metadata": {},
   "source": [
    "### Joining mit Index\n",
    "\n",
    "- Natural Join: R(X,Y) ⋈ S(Y,Z)\n",
    "- Algorithmus\n",
    "    - S habe Index auf Y.\n",
    "    - Lese jeden Block in R.\n",
    "    - Für jedes Tupel: Extrahiere Y-Wert und verwende Index um entsprechendes S-Tupel zu finden\n",
    "- Kosten\n",
    "    - Falls R clustered: B(R)\n",
    "    - Für jedes der T(R) Tupel muss man durchschnittlichT(S)/V(S,Y) Tupel lesen.\n",
    "        - Falls Index nicht clustering ist: T(R) · T(S)/V(S,Y)\n",
    "        - Falls Index clustering: T(R) · B(S)/V(S,Y) bzw. genauer: T(R) · max[ 1 , B(S) / V(S,Y)]\n",
    "        - Dominiert Kosten B(R) bzw. T(R)\n",
    "        \n",
    "**Joining mit Index – Beispiel**\n",
    "- B(R) = 1000, B(S) = 500, T(R) = 10000, T(S) = 5000\n",
    "    - 10 Tupel pro Block\n",
    "- V(S,Y) = 100 (also 100 distinct Y-Werte in S)\n",
    "- R sei clustered; Index auf S[Y] sei clustering\n",
    "- I/O-Kosten:\n",
    "    - 1000 zum Lesen von R\n",
    "    - 10000 · 500/100 = 50000 I/Os zum Vergleich mit S\n",
    "- Diskussion\n",
    "    - Klappt besser falls R sehr klein => Viele Blöcke von S werden nie angefasst\n",
    "    - Bei Hash- und Sort-basierten Methoden werden hingegen immer ganz R und ganz S betrachtet\n",
    "    \n",
    "    \n",
    "**Joining mit sortiertem Index**\n",
    "- Sortierter, dichtbesetzter Index, z.B. B-Baum\n",
    "- Idee 1: Sort-Merge-Join, aber nur eine Relation muss vorher sortiert werden.\n",
    "- Idee 2: Falls beide Relationen sortierten Index auf Y haben: Nur noch Merge-Phase\n",
    "    - „Zig-Zag-Join“\n",
    "    - Tupel aus R ohne Joinpartner in S werden nie gelesen (und umgekehrt)\n",
    "    \n",
    "**Joining mit Indizes – Beispiel**\n",
    "\n",
    "-  B(R) = 1000, B(S) = 500, T(R) = 10000, T(S) = 5000, M = 100\n",
    "- Idee 1: Seien R und S clustered; S habe sortierten Index auf Y; R habe keinen Index\n",
    "    - 10 sortierte Teillisten für R: 2000 I/Os\n",
    "    - Nun 11 Puffer: Einen für jede Teilliste, einen für Blöcke aus S\n",
    "        - Ganz R und ganz S werden gelesen: 1500 I/Os\n",
    "    - Zusammen 3500 I/O\n",
    "        - Wieder weniger als bisher! Aber sortierter Index wird vorausgesetzt…\n",
    "- Idee 2: Nun habe R auch einen Index\n",
    "    - Sortierung der Relationen ist unnötig: Zig-Zag-Join\n",
    "    - Schlimmstenfalls nur ganz R und ganz S lesen: 1500 I/O\n",
    "    - Bei wenigen Joinpartnern: Viel weniger I/Os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b084b821",
   "metadata": {},
   "source": [
    "## Zusammenfassung\n",
    "\n",
    "- Physische Operatoren\n",
    "- One-Pass Algorithmen\n",
    "- Nested Loop Join\n",
    "- Sort-basierte Two-Pass Algorithmen\n",
    "- Hash-basierte Two-Pass Algorithmen\n",
    "- Index-basierte Algorithmen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
