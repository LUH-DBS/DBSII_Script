{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc1e2ae0",
   "metadata": {},
   "source": [
    "# Speicherung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7637b7-44b5-4eee-a047-9d60c7496070",
   "metadata": {},
   "source": [
    "Physische Speicherstrukturen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d210d3f0-daac-4f48-a849-191a49a7473e",
   "metadata": {},
   "source": [
    "Zoom in die interne Ebene: Die 5-Schichten Architektur\n",
    "\n",
    "<img src=\"pictures/5-Schichten-Architektur.png\" alt=\"5-Schichten-Architektur\" width=\"500\" style=\"background-color: white;\"/>\n",
    "\n",
    "Auf der Datenmodellebene können Relationen definiert und die Relationale Algebra verwendet werden. Darunter liegt die logische Ebene. Auf dieser Ebene kann betrachtet werden, wo die Daten liegen bzw. wie diese verteilt sind. Die nächsten Ebenen kümmeren sich um die Speicherstrukturen, also wo die Daten physisch abgelegt wurden und über welche Puffer bzw. Schnittstellen auf diese zugegriffen werden kann. Unter diesen Ebenen liegt noch eine weitere Schnittstelle zum Betriebssystem. Dabei gibt es zwei Varianten wie man mit einem Betriebssystem umgeht. Bei der einen Variante versucht man mit dem System zusammenzuarbeiten, bei der anderen versucht man es zu umgehen. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f7fb2a-8789-4019-872c-b9ae06f58b65",
   "metadata": {},
   "source": [
    "## Speicherhierarchie\n",
    "\n",
    "<img src=\"pictures/Speicherhierachie.png\" alt=\"Speicherhierachie\" width=\"300\" style=\"background-color: white; float: left;\"/>\n",
    "\n",
    "| Speichermedium | Kosten | Zugriffszeiten | Kapazitäten |\n",
    "|---|---|---|---|\n",
    "| Register | Sehr teuer | < 1ns | 10KB |\n",
    "| Cache | Sehr teuer | 1-10ns | 10MB |  \n",
    "| Hauptspeicher | ~ 5€/GB | 100ns | 100GB | \n",
    "| Festplatte | ~ 0.05€/GB | SSDs 100us </br> Festplatte 8-10ms | SSDs 5TB </br> Festplatte 50 TB | \n",
    "| Archivspeicher | < 1€/GB | sec - min | ~ 1PB |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab850f6-b9d9-4866-bd33-4683524f9466",
   "metadata": {},
   "source": [
    "Die Pyramide zur Speicherhierachie soll veranschaulichen, wie sich die Kosten, Zugriffszeiten und Kapazitäten der unterschiedlichen Speichermedien verhalten. <br>\n",
    "In Anbetracht der Kosten sind Archivspeicher sehr günstig verglichen mit Registern, die die teuerste Speicherform in dieser Pyramide darstellen. <br>\n",
    "Bei den Zugriffszeiten wiederrum ist der Archivspeicher am langsamsten und braucht Sekunden, wenn nicht Minuten. Wohingegen Register sehr schnelle Zugriffszeiten unter 1ns ermöglichen. <br>\n",
    "In Bezug auf die Kapazität, bietet der Archivspeicher am meisten Speicherplatz. Ein Register hat mit 10kB beispielsweise deutlich weniger zur Verfügung. <br><br>\n",
    "~ Zahlen aus dem Foliensatz von Viktor Leis 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7ff752-d951-4441-bb2d-e2cad9f270e6",
   "metadata": {},
   "source": [
    "### Virtueller Speicher\n",
    "Jede Anwendung verwaltet einen virtuellen Adressraum. Dieser kann größer als der tatsächlich verfügbare Hauptspeicher sein. \n",
    "Mit einem 32-bit Adressraum sind 2^32 unterschiedliche Adressen darstellbar.\n",
    "Jedes Byte hat dabei eine eigene Adresse. Dadurch lässt sich maximal eine Hauptspeichergröße von 4GB addressieren.  \n",
    "Heutzutage ist der 64-bit Adressraum der Standard. Damit lassen sich maximal 16 Exabyte addressieren. Dies ist deutlich mehr als ein gewöhlicher Computer/Laptop mit 1 oder 2 TB Speicher. Eine 64-bit Addressierung bietet somit noch deutlich mehr Potenzial. <br>\n",
    "Meistens ist aber deutlich weniger Hauptspeicher als Speicher auf der Festplatte vorhanden. Zur Abhilfe werden die Daten auf eine Disk ausgelagert. \n",
    "Dazu müssen ganze Blöcke (Blockgröße zwischen 4 bis 56 KB) zwischen Hauptspeicher und Festplatte gelesen und geschrieben werden (Seiten des virtuellen Speichers). Es werden nicht einzelne ASCII-Zeichen, sondern ganze Blöcke, die beispielsweise mehrere ASCII-Zeichen enthalten, gelesen. Die Transferzeiten ändern sich nämlich kaum, wenn Blöcke anstelle von einzelnen Zeichen gelesen und geschreiben werden. Es können nicht beliebig viele Zeichen in einem Block sein. Irgendwann ist auch das zu viel. <br>\n",
    "Die Zugriffe werden durch ein Betriebssystem verwaltet und eingeschränkt. \n",
    "Datenbankensysteme können Begriffe wie 'O_DIRECT' verwenden, um doch selbst die Positionen der Daten auf den Festplatten zu verwalten und eigene Bufferpoolmanager zu verwenden. Ein Betriebssystem hat beispielsweise mehrere Anwendungen für die es den Hauptspeicher verwalten muss. Daher kann es sein, dass das Betriebssystem eine Anwendung vorzieht, bevor es die Daten aus der Datenbank bearbeitet. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5de828-9c31-4671-ac8b-1abd08c9ca1a",
   "metadata": {},
   "source": [
    "### Sekundärspeicher: Festplatten\n",
    "Unter Sekundärspeicher fallen nicht nur (magnetische) Festplattens, sondern auch optische (read-only) Speicher.\n",
    "Im Wesentlichen gibt es auf Sekundärspeicher wahlfreien Zugriff (random access). Dabei kostet der Zugriff auf jedes Datum gleich viel, aber dafür muss man dort erst einmal hinkommen! <br>\n",
    "HDDs halten Daten aus Cache bzw. die Seiten des virtuellen Speichers von Anwendungsprogrammen. Außerdem halten sie Daten aus Dateisystemen. <br>\n",
    "Es gibt zwei Operationen auf Festplatten. Zum Einem Disk-read. Darunter versteht man das Kopieren eines Blocks in den Hauptspeicher. Zum Anderen Disk-write, dem Kopieren eines Blocks aus dem Hauptspeicher auf die Festplatte. Beides gilt jeweils als eine Disk-I/O-Operation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb5ce7a-edb8-4317-b44b-f3840eb11867",
   "metadata": {},
   "source": [
    "### Festplatten - Puffer\n",
    "Ein Bufferpool-Manager puffert Teile von Dateien. In diesem Beispiel mit einer  Blockgröße von 4 KB. Dabei werden immer 4KB in den Pool geladen. Dieser Block kann dann geschrieben oder auch verworfen werden. \n",
    "\n",
    "  <img src=\"pictures/Festplatten-Puffer.png\" alt=\"Festplatten-Puffer\" width=\"500\" style=\"background-color: white;\"/>\n",
    "\n",
    "Das DBMS verwaltet die Positionen der Blöcke innerhalb der Datei selbst! Dafür ist nicht mehr das Betriebssystem zuständig. <br>\n",
    "Die Dauer für das Schreiben oder Lesen eines Blocks beträgt 10 bis 30 ms. In dieser kurzen Zeitspanne können viele Millionen Prozessoranweisungen ausgeführt werden. Somit dominiert das Lesen und Schreiben, also die I/O-Zeit, die Gesamtkosten. Die Blöcke sollten daher am besten im Hauptspeicher liegen. Das ist nicht immer möglich, da der Hauptspeicher meist zu klein ist. \n",
    "<br><br>\n",
    "Die zuvor genannten Zahlen können je nach Betriebssystem variieren. Sie sind hier aber immer ungefähr im gleichen Skalierungsraum und sollen dabei helfen ein Gefühl für die Zugriffszeiten zu vermitteln. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8006d69-ba8a-40bb-acc4-6d1f5d1a93ab",
   "metadata": {},
   "source": [
    "### Tertiärspeicher: Magnetbänder\n",
    "\n",
    "Tertiärspeicher kann viele Terabyte (10^12 Bytes) Verkaufsdaten, sowie viele Petabyte (10^15 Bytes) Satellitenbeobachtungsdaten speichern. Für diesen Einsatzbereich wären Festplatten ungeeignet. Sie sind zu teuer aufgrund von Wartung und Strom. <br>\n",
    "Im Vergleich zum Sekundärspeicher sind zwar die I/O-Zeiten wesentlich höher, aber dafür steigt auch die Kapazität. Ein weiterer Vorteil sind die geringeren Kosten pro Byte gegenüber den Festplatten. <br>\n",
    "Auf Tertiärspeicher gibt es keinen wahlfreien, sondern zufälligen Zugriff (random access). Die Zugriffszeiten hängen dabei stark von der Position des jeweiligen Datensatzes (in Bezug auf die aktuelle Position des Schreib-/Lesekopfes) ab.\n",
    "\n",
    "<img src=\"pictures/Magnetband.png\" alt=\"Magnetband\" width=\"300\" style=\"background-color: white;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c6d9c6-4ae4-4d35-832f-8d3bce107f78",
   "metadata": {},
   "source": [
    "### Tertiärspeicher\n",
    "\n",
    "Ad-hoc können Daten auf Magnetbändern/Magnetbandspulen und Kasseten gespeichert werden. Die Speichermedien werden oft von Menschenhand in die jeweiligen Regale gelegt und geordnet. Daher der Tertiärspeicher in dem Fall gut beschriftet werden. Durch Magnetbandroboter (Silo) kann dieser Prozess ersetzt bzw. optimiert werden. Der Roboter bedient anstelle des Menschen die Magnetbänder (Kassetten). Der Einsatz von Robotern beschleunigt das Verfahren um das zehnfache. <br>\n",
    "Die Idee ist ähnlich zu CDs, DVDs und Juke-Boxes. Ein Roboterarm extrahiert das jeweilige Medium (CD oder DVD). Der Tertiärspeicher hat wieder eine hohe Lebensdauer von ca. 30 Jahren. Somit ist es wahrscheinlicher, dass kein Lesegerät mehr existiert, als dass der Tertiärspeicher nicht mehr funktioniert. \n",
    "  \n",
    "   <img src=\"pictures/Tertiärspeicher.png\" alt=\"Tertiärspeicher\" width=\"300\" style=\"background-color: white;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85509e3c-a0df-4e8a-adc5-29bf896f2998",
   "metadata": {},
   "source": [
    "### Moore's Law (Gordon Moore, 1965)\n",
    "\n",
    "  <img src=\"pictures/moores-law_1.png\" alt=\"moores-law_1\" width=\"400\" style=\"background-color: white;\"/>\n",
    "  <img src=\"pictures/moores-law_2.png\" alt=\"moores-law_2\" width=\"300\" style=\"background-color: white;\"/>\n",
    "\n",
    "Moore's Law beschreibt das exponentielle Wachstum vieler Parameter. Zu einer Verdopplung kommt es alle 18 Monate. Es können sich beispielsweise die folgenden Parameter verdoppeln bzw. halbieren:\n",
    "  - Prozessorgeschwindigkeit (# instr. per sec.)\n",
    "  - Hauptspeicherkosten pro Bit\n",
    "  - Anzahl Bits pro cm² Chipfläche\n",
    "  - Diskkosten pro Bit (halbiert)\n",
    "  - Kapazität der größten Disks\n",
    "  \n",
    "Dahingegen kommt es aber zu einer sehr langsamen Verbesserung bei der Zugriffsgeschwindigkeit im Hauptspeicher und der Rotationsgeschwindigkeit von Festplatten, da es physikalisch deutlich schwerer und teurer ist zu realisieren. Als Folge daraus wächst der Latenz-Anteil. Die Bewegung von Daten innerhalb der Speicherhierarchie erscheint immer langsamer (im Vergleich zur Prozessorgeschwindigkeit).\n",
    "\n",
    "<img src=\"pictures/moores-law_3.png\" alt=\"moores-law_3\" width=\"500\" style=\"background-color: white;\"/>\n",
    "\n",
    "In dem Diagramm ist die Anzahl der Transistoren in Abhängigkeit der Zeit dargestellt worden. \n",
    "\n",
    "<img src=\"pictures/moores-law_4.png\" alt=\"moores-law_4\" width=\"500\" style=\"background-color: white;\"/>\n",
    "\n",
    "See also: http://www.computerhistory.org/timeline/memory-storage/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c896804-8f29-4954-b8bc-a331f697a42e",
   "metadata": {},
   "source": [
    "### Plattenkapazität\n",
    "\n",
    "<img src=\"pictures/Plattenkapazität.png\" alt=\"Plattenkapazität\" width=\"500\" style=\"background-color: white;\"/>\n",
    "\n",
    "http://en.wikipedia.org/wiki/Hard_disk_drive\n",
    "\n",
    "Wie man aus diesem Diagramm entnehmen kann, wächst die Plattenkapazität exponentiell. <br>\n",
    "Die Zugriffszeiten hingegen gleichen sich langsam an. Im folgendem Bild wird der Trend zur maximal anhaltenden Bandbreite gezeigt.\n",
    "\n",
    "<img src=\"pictures/Access_times.png\" alt=\"Access_times\" width=\"500\" style=\"background-color: white;\"/>\n",
    "\n",
    "\n",
    "Auch die Suchzeiten halbieren sich immer seltener. Daraus ergibt sich der folgende Trend:\n",
    "\n",
    "<img src=\"pictures/Seek_times.png\" alt=\"Seek_times\" width=\"500\" style=\"background-color: white;\"/>\n",
    "\n",
    "\n",
    "http://www.storagenewsletter.com/news/disk/hdd-technology-trends-ibm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720955ea-b33f-4824-9f53-42619525667e",
   "metadata": {},
   "source": [
    "### SSDs\n",
    "Die persistente Speicherung von SSDs basiert auf Halbleitern. Sie haben keine mechanische Bewegung oder Rotation. Außerdem bieten SSDs einen hohen Grad an Parallelität. \n",
    "  \n",
    "  <img src=\"pictures/SSDs.png\" alt=\"SSDs\" width=\"500\" style=\"background-color: white;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21865c7-bdb7-4dfa-9260-9d83070a8faa",
   "metadata": {},
   "source": [
    "### HDDs vs. SSDs\n",
    "\n",
    "Im Vergleich zu HDDs bieten SSDs einige Vorteile:\n",
    "- Schnelles Hochfahren, da keine Drehung erforderlich.\n",
    "- Schneller Random Access ohne Suchzeit.\n",
    "- Geringe Leselatenz.\n",
    "- Lesezeit immer fast gleich.\n",
    "- Keine Probleme durch Dateifragmentierung.\n",
    "- Stille Operationen.\n",
    "- Weniger Stromverbrauch.\n",
    "- Mechanische Zuverlässigkeit.\n",
    "- Immun gegen Magnete.\n",
    "- Weniger Gewicht.\n",
    "- Parallele Lesezugriffe.\n",
    "\n",
    "SSDs besitzen aber auch Nachteile, die bei der Wahl zwischen HDD und SSD berücksichtigt werden sollten:\n",
    "- Begrenzte Lebenszeit.\n",
    "- Verliert Daten nach 2-5 Jahren ohne Strom.\n",
    "- Können nicht defragmentiert werden.\n",
    "- Teuer.\n",
    "- Weniger Kapazität.\n",
    "- Asymmetrische Lese/Schreibgeschwindigkeit aufgrund der Flashtechnologie.\n",
    "- Leistung von SSDs schwindet mit der Zeit.\n",
    "- SATA-basierte SSDs haben sehr langsame Schreiboperationen.\n",
    "- DRAM-basierte SSDs benötigen mehr Strom als HDDs.\n",
    "- Kein sicheres Überschreiben.\n",
    "\n",
    "Über weitere Vor- und Nachteile können Sie <a href=\"https://databasearchitects.blogspot.com/2021/06/what-every-programmer-should-know-about.html\">hier</a> weiterlesen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb22ab6-fa4a-4bb8-a3f8-3404e5ef37d2",
   "metadata": {},
   "source": [
    "## Festplatten\n",
    "<img src=\"pictures/Festplatten_Vergleich_Früher_Heute.png\" alt=\"Festplatten_Vergleich_Früher_Heute\" width=\"400\" style=\"background-color: white;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e4c6c5-003a-414b-83e7-8734f0271ac9",
   "metadata": {},
   "source": [
    "### Aufbau\n",
    "\n",
    "Eine Festplatte besteht aus mehreren (5-10) gleichförmig rotierenden Platten (z.B. 3.5\" Durchmesser). Für jede Plattenoberfläche (10-20) gibt es einen Schreib-/Lese-Kopf, der sich gleichförmig bewegt. Die magnetische Plattenoberfläche ist in Spuren eingeteilt.\n",
    "Spuren sind als Sektoren fester Größe formatiert, wobei sich die Anzahl der Sektoren pro Spur unterscheiden kann. Übereinander angeordnete Spuren bilden einen Zylinder. Die Platten sind übereinander angeordnet, um Zugriffseffizienz zu ermöglichen. Der Kopf kann parallel auch an anderen Stellen lesen und schreiben. \n",
    "\n",
    "<img src=\"pictures/Aufbau_1.png\" alt=\"Aufbau_1\" width=\"500\" style=\"background-color: white;\"/>\n",
    "<img src=\"pictures/Aufbau_2.png\" alt=\"Aufbau_2\" width=\"500\" style=\"background-color: white;\"/>\n",
    "\n",
    "Die Sektoren (1-8 KB) sind die kleinste physische Leseeinheit. Die Größe eines Sektors wird vom jeweiligen Hersteller festgelegt. Auf den äußeren Spuren befinden sich mehr Sektoren als auf den inneren.\n",
    "Zwischen den Sektoren existieren Lücken. Sie sind nicht magnetisiert und dienen zum Auffinden der Sektoranfänge. Diese Lücken nehmen etwa 10% der gesamten Spur ein. </br>\n",
    "Aus den Sektoren lesen wir Blöcke. Blöcke sind die logische Übertragungseinheit. Es ist also die Einheit, die wir auf einmal in den Hauptspeicher laden. Ein Block kann auch aus mehreren Sektoren bestehen.\n",
    "  \n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/7/75/Hard_disk_head.jpg\" alt=\"Aufbau_3\" width=\"500\" style=\"background-color: white;\"/>\n",
    "  \n",
    "<img src=\"pictures/Aufbau_4.png\" alt=\"Aufbau_4\" width=\"500\" style=\"background-color: white;\"/>\n",
    "    \n",
    "Hier in dieser Grafik hat jede Spur die gleiche Anzahl an Sektoren. Normalerweise haben die inneren weniger und die äußeren Spuren mehr Sektoren. Eine Ausnahme wäre es, wenn die Sektoren unterschiedlich groß sind. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57204ac8-d09b-4b7d-a4a9-0c8c2fb82d4d",
   "metadata": {},
   "source": [
    "### Zone Bit Recording\n",
    "\n",
    "Mehrere Spuren übereinander betrachtet ergeben einen Zylinder. Die äußeren Zylinder haben einen größeren Radius und somit auch mehr Fläche. Bei gleichen Radii führt dies zu einer (nicht notwendigen) niedrigeren Bitdichte.\n",
    "Die Lösung sind Zonen mit unterschiedlichen Sektoreinteilungen.\n",
    "Für die folgenden Berechnungen ignorieren wir diesen Fall.\n",
    "\n",
    "<img src=\"pictures/ZoneBitRecording.png\" alt=\"ZoneBitRecording\" width=\"500\" style=\"background-color: white;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9d87c5-b457-485d-a193-5ddce0b4271f",
   "metadata": {},
   "source": [
    "### Disk Controller\n",
    "\n",
    "Ein Disk Controller kontrolliert eine oder mehrere Disks und die Bewegung der Schreib-/Lese-Köpfe. \n",
    "Außerdem wählt er die Plattenoberfläche, auf die zugegriffen werden muss und den Sektor innerhalb der Spur, die sich aktuell unter dem Schreib-/Lese-Kopf befindet. Dadurch kontrolliert er Start und Ende eines Sektors.\n",
    "Der Disk Controller überträgt noch Bits zwischen Disk und Hauptspeicher und umgekehrt.\n",
    "\n",
    "<img src=\"pictures/DiskController.png\" alt=\"DiskController\" width=\"500\" style=\"background-color: white;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c2b398-c849-4013-8ddd-00d6c94967e8",
   "metadata": {},
   "source": [
    "### Beispiel - Megatron 747 disk\n",
    "\n",
    "Ein Beispiel ist die Megatron 747 Disk mit den folgenden Eigenschaften: </br>\n",
    "Sie hat 8 Platten mit 16 Plattenoberflächen. Der Durchmesser beträgt 3,5 Zoll.\n",
    "Sie hat 2^16 = 65.536 Spuren pro Oberfläche, durchschnittlich 2^8 = 256 Sektoren pro Spur und 2^12 = 4.096 Byte pro Sektor.</br></br>\n",
    "Die Gesamtkapazität ergibt sich durch multiplizieren von #Plattenoberflächen, Spuren pro Oberfläche, Sektoren pro Spur und Byte pro Sektor: 16 x 65.536 x 256 x 4.096 = 2^40 Byte = 1 TB. Insgesamt hat die Megatron eine Gesamtkapazität von einem Terrabyte. </br></br>\n",
    "Die Blöcke können beispielsweise eine Größe von 2^14 Byte (= 16 KB) haben. Dann passen 4 Sektoren in einen Block (2^14 / 2^12) und es gibt im Durchschnitt 64 Blöcke pro Spur (2^8 / 2^2). </br></br>\n",
    "Die Bitdichte für die äußerste Spur wird wie folgt berechnet:\n",
    "- Bits pro Spur: 28 Sektoren x 2^12 Byte = 2^20 = 1024 KB = 8 MBit\n",
    "- Die Spurlänge (äußerste Spur) beträgt 3,5“ · p ≈ 11‘‘\n",
    "- mit ca. 10% Lücken hat man eine Spurlänge von 9,9‘‘, die 8 MBits hält\n",
    "\n",
    "Somit sind 840.000 Bits pro Zoll vorhanden. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd6a712-0e56-4d5e-92ed-6cb0c564d5c6",
   "metadata": {},
   "source": [
    "### Disk-Zugriffseigenschaften\n",
    "\n",
    "Eine Voraussetzung für den Zugriff auf einen Block (lesend oder schreibend) ist, dass der S-/L-Kopf auf den richtigen Zylinder positioniert ist, der die Spur mit dem Block enthält. Dann muss die Disk so rotieren, dass Sektoren, die der Block enthält, unter den S-/L-Kopf gelangen. </br>\n",
    "Hierbei sprechen wir von der Latenzzeit. Sie beschreibt die Zeit zwischen der Anweisung einen Block zu lesen und bis zum Eintreffen des Blocks im Hauptspeicher."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f94d5df-f839-48d7-a53b-9ad3d5c9c845",
   "metadata": {},
   "source": [
    "### Latenzzeit\n",
    "\n",
    "- Latenzzeit setzt sich aus der Summe von vier Komponenten zusammen:\n",
    "    1. Kommunikationszeit zwischen Prozessor und Disk Controller:\n",
    "       - Es beträgt nur den Bruchteil einer Millisekunde und kann daher bei Berechnungen hier ignoriert werden. \n",
    "\n",
    "    2. Seektime (Suchzeit) zur Positionierung des Kopfes unter richtigem Zylinder:\n",
    "       - Die Suchzeit ist zwischen 0 und 40 ms ( proportional zum zurückgelegten Weg).\n",
    "       - Sie setzt sich zusammen aus Startzeit (1 ms), Bewegungszeit (0 – 40 ms) und Stopzeit (1 ms).\n",
    "\n",
    "    3. Rotationslatenzzeit zur Drehung der Disk bis der erste Sektor des Blocks unter S-/L-Kopf liegt:\n",
    "       - Durchschnittlich benötigt es eine halbe Umdrehung (4 ms) bis der erste Sektor des Blocks unter dem S-/L-Kopf liegt.\n",
    "       - Es ist eine Optimierung durch Spur-Cache im Disk-Controller möglich.\n",
    "\n",
    "    4. Transferzeit zur Drehung der Disk bis alle Sektoren und die Lücken des Blocks unter S-/L-Kopf passiert sind:\n",
    "       - Es wird ca. ein 16 KB-Block in 0.25 ms passiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47295ab-0a7a-434c-ac6b-9768af7aa3a9",
   "metadata": {},
   "source": [
    "### Schreiben und Ändern von Blöcken\n",
    "\n",
    "Das Schreiben von Blöcken ist in Bezug zu Vorgehen und Zeit analog zum Lesen. Um zu überprüfen, ob eine Schreiboperation erfolgreich war, muss eine Rotation gewartet werden. (Die Nutzung von Checksums wird später beschrieben). </br>\n",
    "\n",
    "Das Ändern von Blöcken ist nicht direkt möglich. Sondern geschieht in 4 Schritten:\n",
    "\n",
    "1. Der jeweilige Block wird in den Hauptspeicher gelesen. \n",
    "2. Die Daten auf dem Block werden geändert.\n",
    "3. Der Block wird auf die Festplatte zurückgeschrieben.\n",
    "4. Zum Schluss wird eventuell die Korrektheit der Schreiboperation überprüft\n",
    "\n",
    "Die Zeit für solch eine Operation ergibt sich aus t_read + t_write. Mit ein wenig Glück ist der Kopf noch in der Nähe, wodurch t_write billiger wird. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cd3fab-b920-46f3-94a0-d97edcb78ed6",
   "metadata": {},
   "source": [
    "### Beispiel – Megatron 747 Disk\n",
    "\n",
    "Wie lange dauert es, einen Block (16 KB = 16 384 Byte) zu lesen?\n",
    "Diese Frage soll nun am Beispiel der Megatron 747 Disk beantwortet werden. </br>\n",
    "\n",
    "Die Umdrehungsgeschwindigkeit beträgt 7200 U · min-1. Somit dauert eine Umdrehung 8,33 ms. </br>\n",
    "\n",
    "Zunächst wird die Seektime berechnet: </br>\n",
    "Die Start- und Stopzeit beträgt zusammen eine Millisekunde. </br>\n",
    "Pro 4000 Zylinder wird 1ms benötigt:\n",
    "    - Minimal werden 0 Zylinder übersprungen und man bleibt an der Stelle an der man ist. Dafür werden 0ms benötigt.\n",
    "    - Wenn man eine Spur (Track) überspringt, kostet das 1,00025ms (≈1ms).\n",
    "    - Maximal werden 65.536 Zylinder übersprungen und das kostet 65536/4000 + 1 = 17,38ms.\n",
    "</br>\n",
    "\n",
    "Als nächstes wird die minimale Zeit berechnet, um einen Block zu lesen: </br>\n",
    "Dafür muss der S-/L-Kopf über der richtigen Spur stehen und die Platte schon richtig rotiert worden sein. Ein Block (16KB) ist über 4 Sektoren und 3 Lücken verteilt. Diese müssen gelesen werden. Insgesamt gibt es durchschnittlich 256 Lücken und 256 Sektoren pro Spur (wurde in vorherigem Unterkapitel so definiert). Die Lücken bedecken 36° (10%) einer Spur. Die Sektoren bedecken 324° des Kreises (360°). </br> \n",
    "Das Verhältnis wird berechnet mit 324° x 4 / 256 + 36° x 3 / 256 = 5,48°. Es sind also 5,48° des Kreises durch einen Block bedeckt.\n",
    "5,48° im Verhältnis zur Gesamtrotation (360°) und einer Umdrehung ergeben dann eine Lesezeit von (5,48° / 360°) · 8,33 ms = 0,13 ms.\n",
    "\n",
    "Die maximale Zeit zum Lesen eines Blocks wird in der Präsenzübung vertieft. (Kleiner Spoiler: Sie beträgt 25,84 ms).\n",
    "Die durchschnittliche Zeit können Sie selber erforschen und nachrechnen. (Dabei sollten sie auf ungefähr 10,76 ms kommen)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352ebd92-172a-4a78-b22c-5097ccc14365",
   "metadata": {},
   "source": [
    "## Effiziente Diskoperationen\n",
    "\n",
    "Die Kopfbewegungen sollen möglichst minimiert werden, sodass der Kopf nicht die ganze Zeit von Spur zu Spur oder von Block zu Block hin- und herspringt. Dies zieht gewisse Anforderungen mit sich: Zum Einem sollen die Daten auf der Festplatte sinnvoll liegen. Zum Anderen sollte es Indexstrukturen geben, sodass man nicht Suchen muss. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02282737-3a9f-44fd-b04c-2088d653eb5f",
   "metadata": {},
   "source": [
    "### Algorithmen vs. DBMS\n",
    "\n",
    "Zuvor war die Annahme bei Algorithmen (wie in der Vorlesung 'Datenstrukturen und Algorithmen'), dass die gesamten Daten in den RAM passen (RAM-Berechnungsmodell) und sie auch bereits dort im Hauptspeicher liegen. \n",
    "\n",
    "Die Annahme bei der Implementierung von DBMS ist das I/O-Modell. Die gesamten Daten passen nicht mehr in Hauptspeicher.\n",
    "\n",
    "Die Externspeicher-Algorithmen funktionieren oft anders. Ein guter Externspeicher-Algorithmus muss nicht der beste Algorithmus laut RAM-Modell sein. Sein primäres Entwurfsziel ist es I/O zu vermeiden. \n",
    "\n",
    "Das Gleiche kann auch für Hauptspeicher-Algorithmen gelten. Diese nutzen den Cache aus und berücksichtigen die Cachegröße. Es wird versucht die Lokalität zu nutzen und alle fernerliegende Zugriffe zu vermeiden („maximiere“ Anzahl der Cache Hits)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e36b197-ef33-4394-b658-124bb8f216d4",
   "metadata": {},
   "source": [
    "### I/O-Modell\n",
    "\n",
    "Als Beispiel sei ein einfaches DBMS gegeben. Dieses ist zu groß für den  Hauptspeicher. Es gibt eine Disk, einen Prozessor und viele konkurrierende Nutzer bzw. Anfragen.\n",
    "\n",
    "Der Disk-Controller hält und organisiert eine Warteschlange (Priority Queue) mit Zugriffsaufforderungen auf die Datenbank. Das Abarbeitungsprinzip der Zugriffsaufforderungen ist hierbei first-come-first-served. Generell muss angenommen werden, dass jede Aufforderung zufällig ist. Also der Kopf an einer zufälligen Position ist. \n",
    "\n",
    "Außerdem dominieren die I/O-Kosten. Wir berücksichtigen nicht was im Hauptspeicher geschieht. Die Kosten des Lesens und Bewegens eines Blocks zwischen Disk und Hauptspeicher sind wesentlich größer als die Kosten der Operationen auf den Daten im Hauptspeicher.\n",
    "  \n",
    "Die Anzahl der Blockzugriffe (lesend und schreibend) ist eine gute Approximation der Gesamtkosten und sollte minimiert werden. Anhanddessen kann die Effizienz von Algorithmen beschrieben werden. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f876a5b-0241-44b3-a430-9d72c643a0f1",
   "metadata": {},
   "source": [
    "### Beispiel für das I/O-Modell (1): Indizes\n",
    "\n",
    "Gegeben sei eine Relation R. Die Anfrage sucht nach dem Tupel t mit dem Schlüsselwert k. </br>\n",
    "Es existiert ein Index auf dem Schlüsselattribut. Diese Datenstruktur ermöglicht einen schnellen Zugriff auf einen Block, der t enthält. Es gibt zwei Varianten bei Indizes. Die erste Variante gibt nur an in welchem Block t liegt. Die zweite Variante gibt zusätzlich die Stelle von t innerhalb des Blocks an. Die daraus resultierende Frage: Welche Indexvariante ist besser geeignet? </br></br>\n",
    "\n",
    "Durchschnittlich benötigt es 11 ms um einen 16 KB-Block zu lesen. In dieser Zeit sind viele Millionen Prozessoranweisungen möglich. Die Suche nach k auf dem Block kostet höchstens Tausende Prozessoranweisungen, selbst mit linearer Suche. Wenn der Block in den Hauptspeicher geladen wurde, sind die Suchkosten darauf verschwindend gering im Vergleich zu den I/O-Kosten. </br>\n",
    "Die zusätzlichen Informationen (wie der Index zum Beispiel) in Variante B nehmen mehr Platz ein und verursachen höhere I/O-Kosten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e127e5bc-98e9-4106-9f93-627edd0a4149",
   "metadata": {},
   "source": [
    "### Beispiel für das I/O-Modell (2): Sortierung\n",
    "\n",
    "Es sei eine Relation R mit 10 Millionen Tupeln und verschiedenen Attributen gegeben. Ein Attribut davon ist der Sortierschlüssel, der nicht unbedingt eindeutig ist. Es ist kein Primärschlüssel. In duiesem Beispiel treffen wir die vereinfachende Annahme, dass der Sortierschlüssel eindeutig ist. </br>\n",
    "Gespeichert werden die Daten auf Diskblöcken der Größe 16.384 = 2^14 Byte mit der Annahme, dass 100 Tupel in einen Block passen. Damit wäre die Tupelgröße ca. 160 Byte. R belegt dann 100.000 Blöcke (1,64 Mrd. Bytes) auf der Festplatte. </br>\n",
    "Es wird eine Megatron 747 Festplatte verwendet.\n",
    "Der verfügbare Hauptspeicherpuffer beträgt 100 MB (= 100 · 2^20). Somit passen (100 * 2^20) / (2^14) = 6400 Blöcke von R passen in den Hauptspeicher. </br>\n",
    "Ziel der Sortierung ist es die Anzahl der Lese- und Schreiboperationen zu minimieren und wenig \"Durchläufe\" durch die Daten zu haben."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3bc269-dc70-49ef-b162-f5a60d52269a",
   "metadata": {},
   "source": [
    "### Merge Sort\n",
    "\n",
    "Merge Sort ist ein Hauptspeicher-Algorithmus und fällt unter die Divide-and-Conquer Algorithmen. Die Idee ist es l ≥ 2 sortierte Listen zu einer größeren sortierten Liste zusammenzumergen. Dazu wählt man aus den sortierten Listen stets das kleinste Element und fügt es der großen Liste hinzu.\n",
    "\n",
    "| | Liste 1 | Liste 2 | Outputliste |\n",
    "|-|-|-|-|\n",
    "| 1. | 1,3,4,9 | 2,5,7,8 | - |\n",
    "| 2. | 3,4,9 | 2,5,7,8 | 1 |\n",
    "| 3. | 3,4,9 | 5,7,8 | 1,2 |\n",
    "| 4. | 4,9 | 5,7,8 | 1,2,3 |\n",
    "| 5. | 9 | 5,7,8 | 1,2,3,4 |\n",
    "| 6. | 9 | 7,8 | 1,2,3,4,5 |\n",
    "| 7. | 9 | 8 | 1,2,3,4,5,7 |\n",
    "| 8. | 9 | - | 1,2,3,4,5,7,8 |\n",
    "| 9. | - | - | 1,2,3,4,5,7,8,9 |\n",
    "\n",
    "Die Rekursion bei Merge Sort beginnt mit dem beliebigen Aufteilen einer Liste mit mehr als einem Element in zwei gleich lange Listen L1 und L2.\n",
    "Die Teillisten L1 und L2 werden rekursiv sortiert. Danach werden beide Teillisten zu einer sortierten Liste gemerged. </br> \n",
    "</br>\n",
    "Der Aufwand von Merge Sort lässt sich in ein paar Schritten berechnen. Die Eingabegröße ist |R| = n. </br>\n",
    "Das Mergen zweier sortierter Listen L1, L2 kostet: O(|L1| + |L2|) = O(n). </br>\n",
    "Die Rekursionstiefe ist log2(n), da sich in jedem Rekursionsschritt die Listenlänge halbiert. Nach i Schritten sind noch n / 2^i Elemente in der Liste.\n",
    "</br>\n",
    "Ergo er ergibt sich ein Aufwand von O(n log n). Das trifft die untere Schranke für das vergleichsbasierte Sortieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bee58f-cd5f-4f1b-b912-6f9451247f63",
   "metadata": {},
   "source": [
    "### Two-Phase, Multiway Merge-Sort (TPMMS)\n",
    "\n",
    "TPMMS wird in vielen DBMS eingesetzt. Es besteht aus zwei Phasen:\n",
    "\n",
    "**Phase 1** </br>\n",
    "    In der ersten Phase werden jeweils so viele Tupel geladen wie in den Hauptspeicher passen. Die Teilstücke werden im Hauptspeicher sortiert und auf die Festplatte zurückgeschrieben. Das Ergebnis sind viele sortierte Teillisten auf der Festplatte.\n",
    "    \n",
    "**Phase 2** </br>\n",
    "    In der Phase werden alle sortierten Teillisten zu einer einzigen großen Liste gemerged.\n",
    " \n",
    " \n",
    "### TPMMS - Phase 1\n",
    "\n",
    "Der Rekursionsanfang ist nun nicht nur mit einem oder zwei Elementen! Die Sortierung der Teillisten erfolgt bei TPMMS z.B. mit Quicksort, welches im worst-case sehr selten ein Aufwand von O(n^2) hat. </br>\n",
    "</br>\n",
    "Der Ablauf der ersten Phase hat drei Schritte:\n",
    "1. Zunächst wird der verfügbare Hauptspeicher mit Diskblöcken aus der Originalrelation gefüllt \n",
    "2. Die Tupel, die sich im Hauptspeicher befinden, werden sortiert.\n",
    "3. Die sortierten Tupel werden auf die neuen Blöcke der Disk geschrieben. Das Ergebnis ist eine sortierte Teilliste.\n",
    "\n",
    "Ein Beispiel dazu: Seien 6,400 Blöcke im Hauptspeicher; also insgesamt 100,000 Blöcke. Es sind 16 Füllungen des Hauptspeichers erforderlich. Die letzte Füllung ist kleiner. </br>\n",
    "Ein Aufwand von 200,000 I/O-Operationen ergibt sich, da 100,000 Blöcke gelesen und 100,000 Blöcke geschreiben werden. </br>\n",
    "Für eine I/O-Operation wird durchschnittlich eine Zeit von 11 ms benötigt. \n",
    "Insgesamt ergben sich 11 ms * 200,000 = 2,200 s = 37 min. Die Prozessorzeit für das Sortieren ist dabei vernachlässigbar.\n",
    "\n",
    "\n",
    "### TPMMS - Phase 2\n",
    "\n",
    "Die naive Idee von Phase 2 ist das paarweise Mergen von k sortierten Teillisten. Man muss 2 * log2(k) jeden Block (jedes Tupels) Lesen und Schreiben. </br>\n",
    "Im Beispiel: Ein Durchlauf für 16 sortierte Teillisten, einer für 8, einer für 4 und ein letzter für 2 sortierte Teillisten. Insgesamt ist jeder Block an 8 I/O-Operationen beteiligt. Es wird deutlich mehr Zeit benötigt. Eine bessere Idee wäre es nur den ersten Block jeder Teilliste zu lesen:\n",
    "1. Suche den kleinsten Schlüssel unter den ersten Tupeln aller Blöcke (Lineare Suche (lin.), Priority Queue (log.)). \n",
    "2. Bewege dieses Element in den Output-Block (im Hauptspeicher).\n",
    "3. Falls der Output-Block voll ist, schreibe ihn auf die Festplatte.\n",
    "4. Falls ein Input-Block leer ist, lese den nächsten Block aus derselben Liste. Der Aufwand beträgt 2 I/O-Operationen pro Block (und Tupel). Dies dauert ebenfalls 37 Minuten.\n",
    "\n",
    "Die Laufzeit für TPMMS insgesamt beträgt somit 74 Minuten.\n",
    "\n",
    "\n",
    "### Bemerkungen zur Blockgröße\n",
    "\n",
    "Es lässt sich beobachten, dass je größer die Blockgröße ist, desto weniger I/O-Operationen werden benötigt. Die Transferzeit erhöht sich dabei etwas.\n",
    "\n",
    "Das bisherige Beispiel:\n",
    "  - Blockgröße: 16 KB\n",
    "  - &#8709; Latenzzeit: 10,88 ms (davon nur 0,253 ms für Transfer)\n",
    "  \n",
    "Das neue Beispiel mit erhöhter Blockgröße:\n",
    "  - Blockgröße: 512 KB (16 * 32)\n",
    "  - &#8709; Latenzzeit: 20 ms (davon 8 ms für Transfer)\n",
    "  \n",
    "Es werden nur noch 12.500 I/O-Operationen für die Sortierung benötigt. Die Gesamtzeit beträgt 4,16 Minuten. Es ergibt sich eine 17-fache Beschleunigung!\n",
    "\n",
    "</br>\n",
    "Die Nachteile der Blockvergrößerung:\n",
    "    - Blocks sollten sich nicht über mehrere Spuren erstrecken.\n",
    "    - Kleine Relationen nutzen nur Bruchteile eines Blocks, was zu Speicherverschwendung führt.\n",
    "    - Viele Datenstrukturen für Externspeicher bevorzugen die Aufteilung von Daten auf viele kleine Blöcke.\n",
    "\n",
    "\n",
    "### TPMMS – Grenzen\n",
    "\n",
    "Vorweg ein paar Stichpunkte zur Notation:\n",
    "  - Blockgröße: B Bytes\n",
    "  - Hauptspeichergröße (für Blocks): M Bytes\n",
    "  - Tupelgröße: R Bytes\n",
    "</br>\n",
    "\n",
    "Grenzen:\n",
    "- Man kann somit sagen, dass M / B Blöcke in den Hauptspeicher passen.\n",
    "- In Phase 2 wird außerdem Platz für einen Outputblock benötigt.\n",
    "- Phase 1 kann also genau (M / B) - 1 sortierte Teillisten erzeugen. Ebenso oft kann der Hauptspeicher mit Tupeln gefüllt und sortiert werden (in Phase 1). Jede Füllung enthält M / R Tupel. \n",
    "- Maximal können (M / R) * ((M / R) - 1) Tupel sortiert werden. </br>\n",
    "</br>\n",
    "- In dem Beispiel:\n",
    "  - M = 104,857,600 Bytes\n",
    "  - B = 16,384 Bytes\n",
    "  - R = 160 Bytes\n",
    "  - Zusammen ergibt sich eine maximale Eingabegröße von 4.2 Milliarden Tupeln (ca. 0.67 Terabyte)\n",
    "\n",
    "<img src=\"pictures/TPMMS-Grenzen-Visualisierung.png\" alt=\"TPMMS-Grenzen-Visualisierung\" width=\"500\" style=\"background-color: white;\"/>\n",
    "\n",
    "Falls die Eingaberelation noch größer ist, wird eine dritte Phase hinzugefügt. TPMMS wird genutzt, um sortierte Listen der Größe M^2/RB zu erzeugen. In der dritten Phase wird maximal M/B - 1 solcher Listen zu einer sortierten Liste zusammengemerged. Insgesamt sind M^3/RB^2 Tupel sortierbar. Bezogen auf unser Beispiel, gibt es nun eine maximale Eingabegröße von 27 Billionen Tupeln (ca. 4.3 Petabytes). Global betrachtet ist die zweite Phase die zusätzliche Phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f05019-c58e-4275-bbc2-5713764419e4",
   "metadata": {},
   "source": [
    "## Zugriffsbeschleunigung\n",
    "\n",
    "Bisher waren die Annahmen, dass es nur eine Disk gibt und die Blockzugriffe (viele kleine Anfragen) zufällig geschehen. \n",
    "Dafür gibt es verschiedene Verbesserungsideen:\n",
    "  - Blöcke, die gemeinsam gelesen werden, werden auf dem gleichen **Zylinder** platziert, um die Suchzeit zu reduzieren.\n",
    "  - Die Daten werden auf mehrere (kleine) Disks verteilt (**Verteilung**), sodass man unabhängige Schreib-/Leseköpfe hat, die es ermöglichen mehrere (unabhängige) Blockzugriffe gleichzeitig durchzuführen.\n",
    "  - **Spiegelung** von Daten auf mehrere Disks.\n",
    "  - Verwendung eines Disk-**Scheduling**-Algorithmus.\n",
    "  - **Prefetching** von Blöcken: Das Ablegen von Blöcken im Hauptspeicher, die möglicherweise demnächst benötigt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21afcf7e-54c2-41b3-aaec-be5ea55304f7",
   "metadata": {},
   "source": [
    "### Daten gemäß Zylinder organisieren\n",
    "\n",
    "Die Seektime macht ca. 50% der durchschnittlichen Blockzugriffszeit aus.\n",
    "Beim Megatron 747 beträgt die Seektime zwischen 0 und 40 ms.\n",
    "Die Idee dabei ist es die Daten, die zusammen gelesen werden, auf dem gleichen Zylinder zu platzieren. Zum Beispiel die Tupel einer Relation. Falls ein Zylinder nicht ausreicht, werden mehrere nebeneinander liegende Zylinder genutzt. Beim Lesen einer Relation fällt im besten Fall nur einmal die Seektime und Rotationslatenz an. Es wird nun die minimale Zugriffszeit der Disk erreicht: Die Zugriffszeit wird nur noch durch die Transferzeit bestimmt. </br>\n",
    "Ein Zylinder der Megatron 747 fasst 16 x 64 = 1024 Blöcke. Dennoch sind dann 16 Umdrehungen erforderlich (+ 15x seek über je eine Spur)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0c01f1-1c2f-4253-9d70-ff75e6ffaacd",
   "metadata": {},
   "source": [
    "### Zylinderorganisation – Beispiel\n",
    "\n",
    "Ein paar Daten zur Megatron 747-Festplatte:\n",
    "  - Mittlere Transferzeit pro Block: ¼ ms.\n",
    "  - Mittlere seek time: 6,46 ms\n",
    "  - Mittlere Rotationslatenzzeit: 4,17 ms\n",
    "  - 16 Oberflächen mit 65.536 Spuren á 64 Blöcke (durchschnittlich)\n",
    "  \n",
    "Die Sortierung von 10 Mio. Tupeln mittels des TPMMS-Algorithmus dauerte 74 min. 100.000 Blöcke von R belegen 1563 Spuren (98 Zylinder).\n",
    "</br></br>\n",
    "Im ersten Teil der **Phase 1** kommt es zum **Lesen** der Blöcke. Dazu wird der Hauptspeicher (mit 6400 Blöcke) 16 mal gefüllt. Es müssen die Blöcke von 6400/1024 = 6-7 Zylindern gelesen werden, die aber direkt nebeneinander liegen. Der Spurwechsel kostet nur 1ms. Die Reihenfolge beim Lesen der Tupel ist egal, wodurch man sich Rotationslatenzzeit spart. Die Zeit pro Füllung ergibt sich durch:\n",
    "    - 6,46 ms + 6 ms + 6x8ms + 1,6s ≈ 1,6 s\n",
    "    - Also: (1.seek) + (ca. 6 Spurwechsel) + (6 Rotationen) + (Transfer 6400 Blöcke)\n",
    "    - Insgesamt: 1,6s x 16 Füllungen = 26s (<<18min)\n",
    "</br></br>\n",
    "Im zweiten Teil der **Phase 1** kommt es zum **Schreiben**: analog zum Lesen ergibt sich beim Schreiben zusammen 52s. Vorher waren es 37 min. Achtung dabei: Die Rotationslatenz ist hier eigentlich wieder relevant...\n",
    "</br></br>\n",
    "**Phase 2** wird nicht beschleunigt. Es wird aus verschiedenen (verteilten) Teillisten gelesen. Das Schreiben des Ausgabepuffers ist zwar sequentiell, wird aber von Leseoperationen unterbrochen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435980bd-7068-4534-8638-4e1848736a07",
   "metadata": {
    "tags": []
   },
   "source": [
    "54min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737562a3-5990-47f9-b56c-333b0d5e90ba",
   "metadata": {},
   "source": [
    "### Mehrere Disks\n",
    "\n",
    "- Problem: S-/L-Köpfe einer Festplatte bewegen sich stets gemeinsam\n",
    "- Lösung: nutze mehrere Festplatten (mit unabhängigen Köpfen)\n",
    "  - Annahme: Disk-Controller, Hauptspeicher, Bus kommen mit höheren Transferraten klar\n",
    "  - Resultat: Division aller Zugriffszeiten durch Festplattenanzahl\n",
    "- Megatron 737 wie 747, aber nur 2 Platten -> 4 Plattenoberflächen\n",
    "  - Ersetze eine Megatron 747 durch vier Megatron 737\n",
    "  - Verteile R auf vier Festplatten\n",
    "- TPMMS – Phase 1\n",
    "  - Lesen: Von jeder Platte nur ¼ der Daten (1600 Blöcke)\n",
    "    - Günstige Zylinderorganisation: seek time und Rotationslatenz ≈ 0\n",
    "    - 1600 Blöcke × 0,25 ms (mittlere Transferzeit)= 400 ms pro Füllung\n",
    "    - 16 Füllungen x 400 ms = 6,4 s\n",
    "  - Schreiben: Jede Teilliste wird auf 4 Disks verteilt\n",
    "    - Wie Lesen: 6,4 s\n",
    "  - Zusammen nur 13 s\n",
    "    - statt 52 s zuvor; bzw. statt 37 min bei zufälliger Anordnung\n",
    "    \n",
    "TPMMS – Phase 2\n",
    "  - Verteilung nützt zunächst nichts\n",
    "    - Immer wenn Block einer Teilliste abgearbeitet ist, wird nächster Block dieser Teilliste in Hauptspeicher geladen\n",
    "    - -> Erst wenn nächster Block vollständig geladen ist, kann Mergen fortgesetzt werden\n",
    "  - Trick für Lesen: Mergen kann fortgesetzt werden, bevor Block vollständig im Hauptspeicher geladen wurde (erstes Element genügt schon)\n",
    "    - So können potenziell mehrere Blöcke parallel (jeweils einer pro Teilliste) geladen werden -> Verbesserung, wenn diese auf unterschiedlichen Festplatten sind\n",
    "    - Vorsicht: Sehr delikate Implementierung\n",
    "  - Schreiben des Outputs\n",
    "    - Verwende mehrere Output-Blöcke (hier: 4)\n",
    "    - Einer wird gefüllt während die anderen drei geschrieben werden (parallel, wenn Schreiben auf unterschiedliche Festplatten)\n",
    "- Geschätzte Beschleunigung von Phase 2: Faktor 2 bis 3\n",
    "  - Immerhin!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948167a1-ea84-4908-b5d7-7e7d74c28c03",
   "metadata": {},
   "source": [
    "### Spiegelung\n",
    "\n",
    "- Idee: Zwei oder mehr Festplatten halten identische Kopien\n",
    "  - Mehr Sicherheit vor Datenverlust\n",
    "  - Beschleunigter Lesezugriff (bei n Festplatten, bis zu n mal so schnell)\n",
    "- TPMMS, Phase 2, Lesen: Trick wie bei mehreren Disks klappt nicht immer\n",
    "  - Keine Verbesserung, falls Blöcke verschiedener Teillisten auf gleicher Festplatte liegen\n",
    "  - Bei Spiegelung kann garantiert werden, dass immer so viele Blöcke unterschiedlicher Teillisten parallel gefüllt werden wie Spiegelungen vorhanden sind\n",
    "- Weiterer Vorteil, auch ohne Parallelität (weniger als n Blöcke gleichzeitig)\n",
    "  - Auswahl der Festplatte möglich, auf die zugegriffen wird\n",
    "  - Wähle die Festplatte, deren Kopf am dichtesten an relevanter Spur steht\n",
    "- Anmerkungen\n",
    "  - Teuer\n",
    "  - Keine Beschleunigung des Schreibzugriffs (aber auch keine Verlangsamung)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9888e2-3cd7-4f46-ac32-11b3f96f39db",
   "metadata": {},
   "source": [
    "### Disk Scheduling\n",
    "\n",
    "- Idee: Disk-Controller entscheidet, welche Zugriffsanweisungen zuerst ausgeführt werden.\n",
    "  - Nützlich bei vielen kleinen Prozessen, je auf wenigen Blöcken\n",
    "  - OLTP\n",
    "  - Ziel: Erhöhung des Durchsatzes\n",
    "- Elevator Algorithmus\n",
    "  - Fahrstuhl fährt in Gebäude hoch und runter\n",
    "    - Hält an Stockwerken an, wenn jemand ein- oder aussteigen will.\n",
    "    - Dreht um, falls weiter oben/unten keiner mehr wartet.\n",
    "  - Diskkopf streicht über Oberfläche einwärts und auswärts\n",
    "    - Hält an Zylindern an, wenn es eine (oder mehrere) Zugriffsanweisung(en) gibt.\n",
    "    - Dreht um, falls in jeweiliger Richtung keine Anweisungen mehr ausstehen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a4656d-8958-46a9-b3e9-7a7619beac75",
   "metadata": {},
   "source": [
    "### First-First-First-Servce vs. Elevator Algorithmus\n",
    "\n",
    "<img src=\"pictures/FFFS-vs-Elevator-Algo.png\" alt=\"FFFS-vs-Elevator-Algo\" width=\"500\" style=\"background-color: white;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f4be80-cbf7-4a09-8b7d-6cf9d98b4802",
   "metadata": {},
   "source": [
    "### Elevator Algorithmus\n",
    "\n",
    "- Verbesserung steigt mit durchschnittlicher Anzahl von wartenden Anweisungen.\n",
    "  - So viele wartende Zugriffsanweisungen wie Anzahl Zylinder\n",
    "    - Jeder Seek geht über nur wenige Zylinder\n",
    "    - Durchschnittliche seek time (bezogen auf wartende Zugriffsanweisungen) wird verringert\n",
    "  - Mehr Zugriffsanweisungen als Zylinder\n",
    "    - Mehrere Zugriffsanweisungen pro Zylinder\n",
    "    - Sortierung um den Zylinder herum möglich\n",
    "    - Dadurch: Reduzierung der Rotationslatenzzeit\n",
    "- Nachteil (falls Anzahl wartender Anweisungen groß):\n",
    "  - Wartezeiten für einzelnen Zugriffsanweisungen können sehr groß werden!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4318793-9751-4ccf-a488-b27367573aa8",
   "metadata": {},
   "source": [
    "### Prefetching\n",
    "\n",
    "- Idee: Wenn man voraussagen kann, welche Blöcke in naher Zukunft gebraucht werden, kann man sie früh (bzw. während man sie sowieso passiert) in den Hauptspeicher laden.\n",
    "- TPMMS, Phase 2, Lesen: 16 Blöcke für die 16 Teillisten reserviert\n",
    "  - Viel Hauptspeicher frei\n",
    "  - Reserviere zwei Blöcke pro Teilliste\n",
    "    - Fülle einen Block, während der andere abgearbeitet wird\n",
    "    - Wenn einer entleert ist, wechsele zum anderen\n",
    "  - Aber: Laufzeit wird nicht verbessert\n",
    "- Idee: Kombination mit guter Spur- oder Zylinderorganisation\n",
    "  - TPMMS, Phase 1, Schreiben: Schreibe Teillisten auf ganze, aufeinanderfolgende Spuren / Zylinder\n",
    "  - TPMMS, Phase 2, Lesen: Lese ganze Spuren / Zylinder, wenn aus einer Liste ein neuer Block benötigt wird.\n",
    "- Idee für das Schreiben analog:\n",
    "  - Zögere Schreiboperationen hinaus bis ganz Spur / ganzer Zylinder geschrieben werden kann\n",
    "  - Verwende mehrere Ausgabepuffer\n",
    "    - Während einer auf Festplatte geleert wird, in anderen schreiben"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
