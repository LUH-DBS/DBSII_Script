
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>1. Speicherung &#8212; Online-Skript Datenbanksysteme II</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2. Repräsentation" href="../02/repraesentation.html" />
    <link rel="prev" title="Datenbanksysteme II" href="../intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/DBIS_Kurzlogo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Online-Skript Datenbanksysteme II</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Datenbanksysteme II
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   1. Speicherung
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02/repraesentation.html">
   2. Repräsentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03/indizes.html">
   3. Indizes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04/anfrageausfuehrung.html">
   4. Anfrageausführung
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../05/optimierung.html">
   5. Optimierung
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../06/large-scale-data-management.html">
   6. Large Scale Data Management
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/LUH-DBS/GDBS_Script/main/?urlpath=tree/01/speicherung.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/LUH-DBS/GDBS_Script"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/LUH-DBS/GDBS_Script/issues/new?title=Issue%20on%20page%20%2F01/speicherung.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/01/speicherung.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#speicherhierarchie">
   1.1. Speicherhierarchie
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#virtueller-speicher">
     1.1.1. Virtueller Speicher
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sekundarspeicher-festplatten">
     1.1.2. Sekundärspeicher: Festplatten
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#festplatten-puffer">
     1.1.3. Festplatten - Puffer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tertiarspeicher-magnetbander">
     1.1.4. Tertiärspeicher: Magnetbänder
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tertiarspeicher">
     1.1.5. Tertiärspeicher
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#moores-law-gordon-moore-1965">
     1.1.6. Moore’s Law (Gordon Moore, 1965)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#plattenkapazitat">
     1.1.7. Plattenkapazität
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hdds">
     1.1.8. HDDs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ssds">
     1.1.9. SSDs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hdds-vs-ssds">
     1.1.10. HDDs vs. SSDs
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#festplatten">
   1.2. Festplatten
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#aufbau">
     1.2.1. Aufbau
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#zone-bit-recording">
     1.2.2. Zone Bit Recording
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#disk-controller">
     1.2.3. Disk Controller
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#beispiel-megatron-747-disk">
     1.2.4. Beispiel - Megatron 747 Disk
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#disk-zugriffseigenschaften">
     1.2.5. Disk-Zugriffseigenschaften
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#latenzzeit">
     1.2.6. Latenzzeit
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#schreiben-und-andern-von-blocken">
     1.2.7. Schreiben und Ändern von Blöcken
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     1.2.8. Beispiel – Megatron 747 Disk
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#effiziente-diskoperationen">
   1.3. Effiziente Diskoperationen
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algorithmen-vs-dbms">
     1.3.1. Algorithmen vs. DBMS
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#i-o-modell">
     1.3.2. I/O-Modell
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#beispiel-fur-das-i-o-modell-1-indizes">
     1.3.3. Beispiel für das I/O-Modell (1): Indizes
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#beispiel-fur-das-i-o-modell-2-sortierung">
     1.3.4. Beispiel für das I/O-Modell (2): Sortierung
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#merge-sort">
     1.3.5. Merge Sort
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#two-phase-multiway-merge-sort-tpmms">
     1.3.6. Two-Phase, Multiway Merge-Sort (TPMMS)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tpmms-phase-1">
     1.3.7. TPMMS - Phase 1
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tpmms-phase-2">
     1.3.8. TPMMS - Phase 2
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bemerkungen-zur-blockgrosze">
     1.3.9. Bemerkungen zur Blockgröße
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tpmms-grenzen">
     1.3.10. TPMMS – Grenzen
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#zugriffsbeschleunigung">
   1.4. Zugriffsbeschleunigung
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#daten-gemasz-zylinder-organisieren">
     1.4.1. Daten gemäß Zylinder organisieren
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#zylinderorganisation-beispiel">
     1.4.2. Zylinderorganisation - Beispiel
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mehrere-disks">
     1.4.3. Mehrere Disks
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#disk-scheduling">
     1.4.4. Disk Scheduling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#spiegelung">
     1.4.5. Spiegelung
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#first-come-first-serve-vs-elevator-algorithmus">
     1.4.6. First-Come-First-Serve vs. Elevator Algorithmus
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#elevator-algorithmus">
     1.4.7. Elevator Algorithmus
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prefetching">
     1.4.8. Prefetching
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Speicherung</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#speicherhierarchie">
   1.1. Speicherhierarchie
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#virtueller-speicher">
     1.1.1. Virtueller Speicher
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sekundarspeicher-festplatten">
     1.1.2. Sekundärspeicher: Festplatten
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#festplatten-puffer">
     1.1.3. Festplatten - Puffer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tertiarspeicher-magnetbander">
     1.1.4. Tertiärspeicher: Magnetbänder
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tertiarspeicher">
     1.1.5. Tertiärspeicher
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#moores-law-gordon-moore-1965">
     1.1.6. Moore’s Law (Gordon Moore, 1965)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#plattenkapazitat">
     1.1.7. Plattenkapazität
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hdds">
     1.1.8. HDDs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ssds">
     1.1.9. SSDs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hdds-vs-ssds">
     1.1.10. HDDs vs. SSDs
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#festplatten">
   1.2. Festplatten
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#aufbau">
     1.2.1. Aufbau
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#zone-bit-recording">
     1.2.2. Zone Bit Recording
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#disk-controller">
     1.2.3. Disk Controller
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#beispiel-megatron-747-disk">
     1.2.4. Beispiel - Megatron 747 Disk
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#disk-zugriffseigenschaften">
     1.2.5. Disk-Zugriffseigenschaften
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#latenzzeit">
     1.2.6. Latenzzeit
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#schreiben-und-andern-von-blocken">
     1.2.7. Schreiben und Ändern von Blöcken
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     1.2.8. Beispiel – Megatron 747 Disk
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#effiziente-diskoperationen">
   1.3. Effiziente Diskoperationen
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algorithmen-vs-dbms">
     1.3.1. Algorithmen vs. DBMS
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#i-o-modell">
     1.3.2. I/O-Modell
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#beispiel-fur-das-i-o-modell-1-indizes">
     1.3.3. Beispiel für das I/O-Modell (1): Indizes
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#beispiel-fur-das-i-o-modell-2-sortierung">
     1.3.4. Beispiel für das I/O-Modell (2): Sortierung
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#merge-sort">
     1.3.5. Merge Sort
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#two-phase-multiway-merge-sort-tpmms">
     1.3.6. Two-Phase, Multiway Merge-Sort (TPMMS)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tpmms-phase-1">
     1.3.7. TPMMS - Phase 1
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tpmms-phase-2">
     1.3.8. TPMMS - Phase 2
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bemerkungen-zur-blockgrosze">
     1.3.9. Bemerkungen zur Blockgröße
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tpmms-grenzen">
     1.3.10. TPMMS – Grenzen
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#zugriffsbeschleunigung">
   1.4. Zugriffsbeschleunigung
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#daten-gemasz-zylinder-organisieren">
     1.4.1. Daten gemäß Zylinder organisieren
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#zylinderorganisation-beispiel">
     1.4.2. Zylinderorganisation - Beispiel
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mehrere-disks">
     1.4.3. Mehrere Disks
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#disk-scheduling">
     1.4.4. Disk Scheduling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#spiegelung">
     1.4.5. Spiegelung
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#first-come-first-serve-vs-elevator-algorithmus">
     1.4.6. First-Come-First-Serve vs. Elevator Algorithmus
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#elevator-algorithmus">
     1.4.7. Elevator Algorithmus
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prefetching">
     1.4.8. Prefetching
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="speicherung">
<h1><span class="section-number">1. </span>Speicherung<a class="headerlink" href="#speicherung" title="Permalink to this headline">#</a></h1>
<p>Bei der Wahl und dem Design eines Algorithmus ist die Speicherung ein großer Faktor. Das Zusammenspiel aus Größe, Kosten und Zugriffszeiten muss berücksichtigt werden, um teure Operationen und Zugriffe zu minimieren. Deshalb befassen wir uns im ersten Kapitel mit der Speicherung sowie unter anderem mit Speicherstrukturen und -hierarchien, um Algorithmen bestmöglich zu designen und effizient einzusetzen.</p>
<p><strong>Zoom in die interne Ebene: Die 5-Schichten Architektur</strong></p>
<figure class="align-default" id="schichten-architektur">
<img alt="../_images/5-Schichten-Architektur.png" src="../_images/5-Schichten-Architektur.png" />
<figcaption>
<p><span class="caption-number">Fig. 1.1 </span><span class="caption-text">5-Schichten-Architektur</span><a class="headerlink" href="#schichten-architektur" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Auf der Datenmodellebene können Relationen definiert und die relationale Algebra verwendet werden. Darunter befindet sich die logische Ebene. Auf dieser Ebene kann betrachtet werden, wo die Daten liegen bzw. wie sie verteilt sind. Die nächsten zwei Ebenen beschäftigen sich mit den Speicherstrukturen. Also wo die Daten physisch abgelegt sind und über welche Puffer bzw. Schnittstellen darauf zugegriffen werden kann. Unterhalb dieser Ebenen befindet sich noch eine weitere Schnittstelle zum Betriebssystem. Es gibt zwei Varianten, wie man mit einem Betriebssystem umgeht. Bei der einen Variante versucht man mit dem System zu arbeiten, bei der anderen Variante versucht man es zu umgehen.</p>
<section id="speicherhierarchie">
<h2><span class="section-number">1.1. </span>Speicherhierarchie<a class="headerlink" href="#speicherhierarchie" title="Permalink to this headline">#</a></h2>
<figure class="align-default" id="speicherhierachie">
<img alt="../_images/Speicherhierachie.png" src="../_images/Speicherhierachie.png" />
<figcaption>
<p><span class="caption-number">Fig. 1.2 </span><span class="caption-text">Speicherhierachie</span><a class="headerlink" href="#speicherhierachie" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Speichermedium</p></th>
<th class="head"><p>Kosten</p></th>
<th class="head"><p>Zugriffszeiten</p></th>
<th class="head"><p>Kapazitäten</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Register</p></td>
<td><p>Sehr teuer</p></td>
<td><p>&lt; 1ns</p></td>
<td><p>10KB</p></td>
</tr>
<tr class="row-odd"><td><p>Cache</p></td>
<td><p>Sehr teuer</p></td>
<td><p>1-10ns</p></td>
<td><p>10MB</p></td>
</tr>
<tr class="row-even"><td><p>Hauptspeicher</p></td>
<td><p>~ 5€/GB</p></td>
<td><p>100ns</p></td>
<td><p>100GB</p></td>
</tr>
<tr class="row-odd"><td><p>Festplatte</p></td>
<td><p>~ 0.05€/GB</p></td>
<td><p>SSDs 100us </br> Festplatte 8-10ms</p></td>
<td><p>SSDs 5TB </br> Festplatte 50 TB</p></td>
</tr>
<tr class="row-even"><td><p>Archivspeicher</p></td>
<td><p>&lt; 1€/GB</p></td>
<td><p>sec - min</p></td>
<td><p>~ 1PB</p></td>
</tr>
</tbody>
</table>
<p>Die Pyramide zur Speicherhierachie soll veranschaulichen, wie sich die Kosten, Zugriffszeiten und Kapazitäten der unterschiedlichen Speichermedien verhalten. <br>
In Anbetracht der <strong>Kosten</strong> sind Archivspeicher sehr günstig verglichen mit Registern, die die teuerste Speicherform in dieser Pyramide darstellen. <br>
Bei den <strong>Zugriffszeiten</strong> wiederrum ist der Archivspeicher am langsamsten und braucht Sekunden, wenn nicht Minuten. Wohingegen Register sehr schnelle Zugriffszeiten unter 1ns ermöglichen. <br>
In Bezug auf die Kapazität, bietet der Archivspeicher am meisten Speicherplatz. Ein Register hat mit 10kB beispielsweise deutlich weniger zur Verfügung. <br><br>
~ Zahlen aus dem Foliensatz von Viktor Leis 2019</p>
<section id="virtueller-speicher">
<h3><span class="section-number">1.1.1. </span>Virtueller Speicher<a class="headerlink" href="#virtueller-speicher" title="Permalink to this headline">#</a></h3>
<p>Jede Anwendung verwaltet einen virtuellen Adressraum. Dieser kann größer als der tatsächlich verfügbare Hauptspeicher sein.
Mit einem 32-bit Adressraum sind 2^32 unterschiedliche Adressen darstellbar.
Jedes Byte hat dabei eine eigene Adresse. Dadurch lässt sich maximal eine Hauptspeichergröße von 4GB addressieren.<br />
Heutzutage ist der 64-bit Adressraum der Standard. Damit lassen sich maximal 16 Exabyte addressieren. Dies ist deutlich mehr als ein gewöhlicher Computer/Laptop mit 1 oder 2 TB Speicher. Eine 64-bit Addressierung bietet somit noch deutlich mehr Potenzial. <br>
Meistens ist aber deutlich weniger Hauptspeicher als Speicher auf der Festplatte vorhanden. Zur Abhilfe werden die Daten auf eine Disk ausgelagert.
Dazu müssen ganze Blöcke (Blockgröße zwischen 4 bis 56 KB) zwischen Hauptspeicher und Festplatte gelesen und geschrieben werden (Seiten des virtuellen Speichers). Es werden nicht einzelne ASCII-Zeichen, sondern ganze Blöcke, die beispielsweise mehrere ASCII-Zeichen enthalten, gelesen. Die Transferzeiten ändern sich nämlich kaum, wenn Blöcke anstelle von einzelnen Zeichen gelesen und geschreiben werden. Es können nicht beliebig viele Zeichen in einem Block sein. Irgendwann ist auch das zu viel. <br>
Die Zugriffe werden durch ein Betriebssystem verwaltet und eingeschränkt.
Datenbankensysteme können Begriffe wie ‘O_DIRECT’ verwenden, um doch selbst die Positionen der Daten auf den Festplatten zu verwalten und eigene Bufferpoolmanager zu verwenden. Ein Betriebssystem hat beispielsweise mehrere Anwendungen für die es den Hauptspeicher verwalten muss. Daher kann es sein, dass das Betriebssystem eine Anwendung vorzieht, bevor es die Daten aus der Datenbank bearbeitet.</p>
</section>
<section id="sekundarspeicher-festplatten">
<h3><span class="section-number">1.1.2. </span>Sekundärspeicher: Festplatten<a class="headerlink" href="#sekundarspeicher-festplatten" title="Permalink to this headline">#</a></h3>
<p>Unter Sekundärspeicher fallen nicht nur (magnetische) Festplattens, sondern auch optische (read-only) Speicher.
Im Wesentlichen gibt es auf Sekundärspeicher <strong>wahlfreien Zugriff</strong> (random access). Dabei kostet der Zugriff auf jedes Datum gleich viel, aber dafür muss man dort erst einmal hinkommen! <br>
HDDs halten Daten aus Cache bzw. die Seiten des virtuellen Speichers von Anwendungsprogrammen. Außerdem halten sie Daten aus Dateisystemen. <br>
Es gibt zwei Operationen auf Festplatten. Zum Einem <strong>Disk-read</strong>. Darunter versteht man das Kopieren eines Blocks in den Hauptspeicher. Zum Anderen <strong>Disk-write</strong>, dem Kopieren eines Blocks aus dem Hauptspeicher auf die Festplatte. Beides gilt jeweils als eine Disk-I/O-Operation.</p>
</section>
<section id="festplatten-puffer">
<h3><span class="section-number">1.1.3. </span>Festplatten - Puffer<a class="headerlink" href="#festplatten-puffer" title="Permalink to this headline">#</a></h3>
<p>Ein Bufferpool-Manager puffert Teile von Dateien. In diesem Beispiel mit einer  Blockgröße von 4 KB. Dabei werden immer 4KB in den Pool geladen. Dieser Block kann dann geschrieben oder auch verworfen werden.</p>
<figure class="align-default" id="id1">
<img alt="../_images/Festplatten-Puffer.png" src="../_images/Festplatten-Puffer.png" />
<figcaption>
<p><span class="caption-number">Fig. 1.3 </span><span class="caption-text">Festplatten-Puffer</span><a class="headerlink" href="#id1" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Das DBMS verwaltet die Positionen der Blöcke innerhalb der Datei selbst! Dafür ist nicht mehr das Betriebssystem zuständig. <br>
Die Dauer für das Schreiben oder Lesen eines Blocks beträgt 10 bis 30 ms. In dieser kurzen Zeitspanne können viele Millionen Prozessoranweisungen ausgeführt werden. Somit dominiert das Lesen und Schreiben, also die <strong>I/O-Zeit</strong>, die Gesamtkosten. Die Blöcke sollten daher am besten im Hauptspeicher liegen. Das ist nicht immer möglich, da der Hauptspeicher meist zu klein ist.</p>
<p>Die zuvor genannten Zahlen können je nach Betriebssystem variieren. Sie sind hier aber immer ungefähr im gleichen Skalierungsraum und sollen dabei helfen ein Gefühl für die Zugriffszeiten zu vermitteln.</p>
</section>
<section id="tertiarspeicher-magnetbander">
<h3><span class="section-number">1.1.4. </span>Tertiärspeicher: Magnetbänder<a class="headerlink" href="#tertiarspeicher-magnetbander" title="Permalink to this headline">#</a></h3>
<p>Tertiärspeicher kann <strong>viele Terabyte</strong> (10^12 Bytes) Verkaufsdaten, sowie viele Petabyte (10^15 Bytes) Satellitenbeobachtungsdaten speichern. Für diesen Einsatzbereich wären Festplatten ungeeignet. Sie sind zu teuer aufgrund von Wartung und Strom. <br>
Im Vergleich zum Sekundärspeicher sind zwar die <strong>I/O-Zeiten wesentlich höher</strong>, aber dafür steigt auch die Kapazität. Ein weiterer Vorteil sind die geringeren Kosten pro Byte gegenüber den Festplatten. <br>
Auf Tertiärspeicher gibt es keinen wahlfreien, sondern zufälligen Zugriff (<strong>random access</strong>). Die Zugriffszeiten hängen dabei stark von der Position des jeweiligen Datensatzes (in Bezug auf die aktuelle Position des Schreib-/Lesekopfes) ab.</p>
<figure class="align-default" id="magnetband">
<img alt="../_images/Magnetband.png" src="../_images/Magnetband.png" />
<figcaption>
<p><span class="caption-number">Fig. 1.4 </span><span class="caption-text">Magnetband</span><a class="headerlink" href="#magnetband" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="tertiarspeicher">
<h3><span class="section-number">1.1.5. </span>Tertiärspeicher<a class="headerlink" href="#tertiarspeicher" title="Permalink to this headline">#</a></h3>
<p>Ad-hoc können Daten auf Magnetbändern/Magnetbandspulen und Kasseten gespeichert werden. Die Speichermedien werden oft von <strong>Menschenhand</strong> in die jeweiligen Regale gelegt und geordnet. Daher der Tertiärspeicher in dem Fall gut beschriftet werden. Durch Magnetbandroboter (Silo) kann dieser Prozess ersetzt bzw. optimiert werden. Der <strong>Roboter</strong> bedient anstelle des Menschen die Magnetbänder (Kassetten). Der Einsatz von Robotern beschleunigt das Verfahren um das zehnfache. <br>
Die Idee ist ähnlich zu CDs, DVDs und Juke-Boxes. Ein Roboterarm extrahiert das jeweilige Medium (CD oder DVD). Der Tertiärspeicher hat wieder eine <strong>hohe Lebensdauer</strong> von ca. 30 Jahren. Somit ist es wahrscheinlicher, dass kein Lesegerät mehr existiert, als dass der Tertiärspeicher nicht mehr funktioniert.</p>
<figure class="align-default" id="id2">
<img alt="../_images/Tertiärspeicher.png" src="../_images/Tertiärspeicher.png" />
<figcaption>
<p><span class="caption-number">Fig. 1.5 </span><span class="caption-text">Tertiärspeicher</span><a class="headerlink" href="#id2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="moores-law-gordon-moore-1965">
<h3><span class="section-number">1.1.6. </span>Moore’s Law (Gordon Moore, 1965)<a class="headerlink" href="#moores-law-gordon-moore-1965" title="Permalink to this headline">#</a></h3>
<figure class="align-default" id="moores-law-1">
<img alt="../_images/moores-law_1.png" src="../_images/moores-law_1.png" />
<figcaption>
<p><span class="caption-number">Fig. 1.6 </span><span class="caption-text">Moores Law</span><a class="headerlink" href="#moores-law-1" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-default" id="moores-law-2">
<img alt="../_images/moores-law_2.png" src="../_images/moores-law_2.png" />
<figcaption>
<p><span class="caption-number">Fig. 1.7 </span><span class="caption-text">Gordon Moore</span><a class="headerlink" href="#moores-law-2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Moore’s Law beschreibt das exponentielle Wachstum vieler Parameter. Alle 18 Monate findet eine <strong>Verdoppelung</strong> statt. Zum Beispiel können sich folgende Parameter verdoppeln oder halbieren:</p>
<ul class="simple">
<li><p>Prozessorgeschwindigkeit (# instr. per sec.)</p></li>
<li><p>Hauptspeicherkosten pro Bit</p></li>
<li><p>Anzahl der Bits pro cm² Chipfläche</p></li>
<li><p>Diskkosten pro Bit (halbiert)</p></li>
<li><p>Kapazität der größten Disks</p></li>
</ul>
<p>Dahingegen kommt es aber zu einer sehr langsamen Verbesserung bei der Zugriffsgeschwindigkeit im Hauptspeicher und der Rotationsgeschwindigkeit von Festplatten, da es physikalisch deutlich schwerer und teurer ist zu realisieren. Als Folge daraus wächst der Latenz-Anteil. Die Bewegung von Daten innerhalb der Speicherhierarchie erscheint immer langsamer (im Vergleich zur Prozessorgeschwindigkeit).</p>
<figure class="align-default" id="moores-law-3">
<img alt="../_images/moores-law_3.png" src="../_images/moores-law_3.png" />
<figcaption>
<p><span class="caption-number">Fig. 1.8 </span><span class="caption-text">Anzahl Transistoren im Laufe der Zeit</span><a class="headerlink" href="#moores-law-3" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Das Diagramm zeigt die Anzahl der Transistoren als Funktion der Zeit.</p>
<figure class="align-default" id="moores-law-4">
<img alt="../_images/moores-law_4.png" src="../_images/moores-law_4.png" />
<figcaption>
<p><span class="caption-number">Fig. 1.9 </span><span class="caption-text">1 Gigabyte vor einiger Zeit</span><a class="headerlink" href="#moores-law-4" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Siehe auch: <a class="reference external" href="http://www.computerhistory.org/timeline/memory-storage/">http://www.computerhistory.org/timeline/memory-storage/</a></p>
</section>
<section id="plattenkapazitat">
<h3><span class="section-number">1.1.7. </span>Plattenkapazität<a class="headerlink" href="#plattenkapazitat" title="Permalink to this headline">#</a></h3>
<figure class="align-default" id="id3">
<img alt="../_images/Plattenkapazität.png" src="../_images/Plattenkapazität.png" />
<figcaption>
<p><span class="caption-number">Fig. 1.10 </span><span class="caption-text">Plattenkapazität</span><a class="headerlink" href="#id3" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p><a class="reference external" href="http://en.wikipedia.org/wiki/Hard_disk_drive">http://en.wikipedia.org/wiki/Hard_disk_drive</a></p>
<p>Wie man aus diesem Diagramm entnehmen kann, wächst die Plattenkapazität exponentiell. <br>
Die Zugriffszeiten hingegen gleichen sich langsam an. Im folgendem Bild wird der Trend zur maximal anhaltenden Bandbreite gezeigt.</p>
<figure class="align-default" id="access-times">
<img alt="../_images/Access_times.png" src="../_images/Access_times.png" />
<figcaption>
<p><span class="caption-number">Fig. 1.11 </span><span class="caption-text">Access Times</span><a class="headerlink" href="#access-times" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Auch die Suchzeiten halbieren sich immer seltener. Daraus ergibt sich der folgende Trend:</p>
<figure class="align-default" id="seek-times">
<img alt="../_images/Seek_times.png" src="../_images/Seek_times.png" />
<figcaption>
<p><span class="caption-number">Fig. 1.12 </span><span class="caption-text">Seek Times</span><a class="headerlink" href="#seek-times" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p><a class="reference external" href="http://www.storagenewsletter.com/news/disk/hdd-technology-trends-ibm">http://www.storagenewsletter.com/news/disk/hdd-technology-trends-ibm</a></p>
</section>
<section id="hdds">
<h3><span class="section-number">1.1.8. </span>HDDs<a class="headerlink" href="#hdds" title="Permalink to this headline">#</a></h3>
<p><strong>Hard Disk Drives</strong> (auch kurz HDD genannt) sind eine ältere, aber nach wie vor weit verbreitete Form der Datenspeicher. HDDs verwenden eine magnetische Speicherung auf rotierenden Scheiben, die auch Platten genannt werden.</p>
</section>
<section id="ssds">
<h3><span class="section-number">1.1.9. </span>SSDs<a class="headerlink" href="#ssds" title="Permalink to this headline">#</a></h3>
<p>Die persistente Speicherung auf SSDs (<strong>Solid State Drive</strong>) basiert auf Halbleitern. Es gibt keine mechanische Bewegung oder Rotation wie bei einer HDD-Festplatte. Außerdem bieten SSDs einen hohen Grad an Parallelität.</p>
<figure class="align-default" id="id4">
<img alt="../_images/SSDs.png" src="../_images/SSDs.png" />
<figcaption>
<p><span class="caption-number">Fig. 1.13 </span><span class="caption-text">SSDs</span><a class="headerlink" href="#id4" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="hdds-vs-ssds">
<h3><span class="section-number">1.1.10. </span>HDDs vs. SSDs<a class="headerlink" href="#hdds-vs-ssds" title="Permalink to this headline">#</a></h3>
<p>Im Vergleich zu HDDs bieten SSDs einige Vorteile:</p>
<ul class="simple">
<li><p>Schnelles Hochfahren, da keine Drehung erforderlich ist.</p></li>
<li><p>Schneller Random Access ohne Suchzeiten.</p></li>
<li><p>Geringe Leselatenz.</p></li>
<li><p>Immer nahezu gleiche Lesezeit.</p></li>
<li><p>Keine Probleme durch Dateifragmentierung.</p></li>
<li><p>Stille Operationen und leiser Betrieb.</p></li>
<li><p>Geringer Stromverbrauch.</p></li>
<li><p>Mechanische Zuverlässigkeit.</p></li>
<li><p>Immun gegen Magnete.</p></li>
<li><p>Geringeres Gewicht.</p></li>
<li><p>Parallele Lesezugriffe.</p></li>
</ul>
<p>Trotz der wachsenden Beliebtheit von SSDs und ihren Vorteilen bleiben HDDs in verschiedenen Bereichen weiterhin relevant. Grund dafür sind einige Nachteile von SSDs. Diese sollten bei der Entscheidung zwischen HDD und SSD berücksichtigt werden:</p>
<ul class="simple">
<li><p>Begrenzte Lebensdauer.</p></li>
<li><p>Datenverlust nach 2-5 Jahren ohne Strom.</p></li>
<li><p>Können nicht defragmentiert werden.</p></li>
<li><p>Teuer.</p></li>
<li><p>Geringere Kapazität.</p></li>
<li><p>Asymmetrische Lese/Schreibgeschwindigkeit aufgrund der Flash-Technologie.</p></li>
<li><p>Leistung von SSDs nimmt mit der Zeit ab.</p></li>
<li><p>SATA-basierte SSDs haben sehr langsame Schreibvorgänge.</p></li>
<li><p>DRAM-basierte SSDs verbrauchen mehr Strom als HDDs.</p></li>
<li><p>Kein sicheres Überschreiben.</p></li>
</ul>
<p>Über weitere Vor- und Nachteile können Sie <a href="https://databasearchitects.blogspot.com/2021/06/what-every-programmer-should-know-about.html">hier</a> weiterlesen.</p>
</section>
</section>
<section id="festplatten">
<h2><span class="section-number">1.2. </span>Festplatten<a class="headerlink" href="#festplatten" title="Permalink to this headline">#</a></h2>
<figure class="align-default" id="festplatten-vergleich-fruher-heute">
<img alt="../_images/Festplatten_Vergleich_Früher_Heute.png" src="../_images/Festplatten_Vergleich_Früher_Heute.png" />
<figcaption>
<p><span class="caption-number">Fig. 1.14 </span><span class="caption-text">Festplatten im Vergleich: Früher und Heute</span><a class="headerlink" href="#festplatten-vergleich-fruher-heute" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<section id="aufbau">
<h3><span class="section-number">1.2.1. </span>Aufbau<a class="headerlink" href="#aufbau" title="Permalink to this headline">#</a></h3>
<p>Eine Festplatte besteht aus mehreren (5-10) gleichförmig rotierenden <strong>Platten</strong> (z.B. 3.5” Durchmesser). Für jede <strong>Plattenoberfläche</strong> (10-20) gibt es einen Schreib-/Lesekopf, der sich gleichmäßig bewegt. Die magnetische Plattenoberfläche ist in <strong>Spuren</strong> unterteilt.
Spuren sind als <strong>Sektoren</strong> fester Größe formatiert, wobei sich die Anzahl der Sektoren pro Spur unterscheiden kann. Übereinander angeordnete Spuren bilden einen <strong>Zylinder</strong>. Die Platten sind übereinander angeordnet, um Zugriffseffizienz zu ermöglichen. Der Kopf kann parallel auch an anderen Stellen lesen und schreiben.</p>
<figure class="align-default" id="aufbau-1">
<img alt="../_images/Aufbau_1.png" src="../_images/Aufbau_1.png" />
<figcaption>
<p><span class="caption-number">Fig. 1.15 </span><span class="caption-text">Aufbau 1</span><a class="headerlink" href="#aufbau-1" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-default" id="aufbau-2">
<img alt="../_images/Aufbau_2.png" src="../_images/Aufbau_2.png" />
<figcaption>
<p><span class="caption-number">Fig. 1.16 </span><span class="caption-text">Aufbau 2</span><a class="headerlink" href="#aufbau-2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Die <strong>Sektoren</strong> (1-8 KB) sind die kleinste physische Leseeinheit. Die Größe eines Sektors wird vom jeweiligen Hersteller festgelegt. Auf den äußeren Spuren befinden sich mehr Sektoren als auf den inneren.
Zwischen den Sektoren existieren <strong>Lücken</strong>. Sie sind nicht magnetisiert und dienen zum Auffinden der Sektoranfänge. Diese Lücken nehmen etwa 10% der gesamten Spur ein. </br>
Aus den Sektoren lesen wir <strong>Blöcke</strong>. Blöcke sind die logische Übertragungseinheit. Es ist also die Einheit, die wir auf einmal in den Hauptspeicher laden. Ein Block kann auch aus mehreren Sektoren bestehen.</p>
<figure class="align-default" id="aufbau-3">
<img alt="https://upload.wikimedia.org/wikipedia/commons/7/75/Hard_disk_head.jpg" src="https://upload.wikimedia.org/wikipedia/commons/7/75/Hard_disk_head.jpg" />
<figcaption>
<p><span class="caption-number">Fig. 1.17 </span><span class="caption-text">Aufbau 3</span><a class="headerlink" href="#aufbau-3" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-default" id="aufbau-4">
<img alt="../_images/Aufbau_4.png" src="../_images/Aufbau_4.png" />
<figcaption>
<p><span class="caption-number">Fig. 1.18 </span><span class="caption-text">Aufbau 4</span><a class="headerlink" href="#aufbau-4" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Hier in dieser Grafik hat jede Spur die gleiche Anzahl an Sektoren. Normalerweise haben die inneren weniger und die äußeren Spuren mehr Sektoren. Eine Ausnahme wäre es, wenn die Sektoren unterschiedlich groß sind.</p>
</section>
<section id="zone-bit-recording">
<h3><span class="section-number">1.2.2. </span>Zone Bit Recording<a class="headerlink" href="#zone-bit-recording" title="Permalink to this headline">#</a></h3>
<p>Mehrere Spuren übereinander betrachtet bilden einen <strong>Zylinder</strong>. Die äußeren Zylinder haben einen größeren Radius und damit eine größere Fläche. Bei gleichen Radien führt dies zu einer (nicht notwendigen) geringeren Bitdichte.
Die Lösung sind Zonen mit unterschiedlichen Sektoreinteilungen.
Für die folgenden Berechnungen wird dieser Fall vernachlässigt.</p>
<figure class="align-default" id="zonebitrecording">
<img alt="../_images/ZoneBitRecording.png" src="../_images/ZoneBitRecording.png" />
<figcaption>
<p><span class="caption-number">Fig. 1.19 </span><span class="caption-text">Zone Bit Recording</span><a class="headerlink" href="#zonebitrecording" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="disk-controller">
<h3><span class="section-number">1.2.3. </span>Disk Controller<a class="headerlink" href="#disk-controller" title="Permalink to this headline">#</a></h3>
<p>Ein <strong>Disk Controller</strong> steuert eine oder mehrere Disks und die Bewegung der Schreib-/Lese-Köpfe.
Außerdem wählt er die Plattenoberfläche aus, auf die zugegriffen werden soll und den Sektor innerhalb der Spur, die sich gerade unter dem Schreib-/Lese-Kopf befindet. Auf diese Weise kontrolliert er den Start und das Ende eines Sektors.
Der Disk Controller überträgt noch Bits zwischen Disk und Hauptspeicher und umgekehrt.</p>
<figure class="align-default" id="diskcontroller">
<img alt="../_images/DiskController.png" src="../_images/DiskController.png" />
<figcaption>
<p><span class="caption-number">Fig. 1.20 </span><span class="caption-text">Disk Controller</span><a class="headerlink" href="#diskcontroller" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="beispiel-megatron-747-disk">
<h3><span class="section-number">1.2.4. </span>Beispiel - Megatron 747 Disk<a class="headerlink" href="#beispiel-megatron-747-disk" title="Permalink to this headline">#</a></h3>
<p>Ein Beispiel ist die Megatron 747 Disk mit den folgenden <strong>Eigenschaften</strong>:</p>
<p>Sie hat 8 Platten mit 16 Plattenoberflächen. Der Durchmesser beträgt 3,5 Zoll.
Sie hat <span class="math notranslate nohighlight">\(2^{16} = 65.536\)</span> Spuren pro Oberfläche, durchschnittlich <span class="math notranslate nohighlight">\(2^8 = 256\)</span> Sektoren pro Spur und <span class="math notranslate nohighlight">\(2^{12} = 4.096\)</span> Byte pro Sektor.</p>
<p>Die <strong>Gesamtkapazität</strong> ergibt sich durch multiplizieren von #Plattenoberflächen, Spuren pro Oberfläche, Sektoren pro Spur und Byte pro Sektor: <span class="math notranslate nohighlight">\(16 x 65.536 x 256 x 4.096 = 2^{40} Byte = 1 TB\)</span>. Insgesamt hat die Megatron 747 Disk eine Gesamtkapazität von einem Terrabyte.</p>
<p>Die Blöcke können eine Größe von <span class="math notranslate nohighlight">\(2^{14} Byte (= 16 KB)\)</span> haben. Dann passen 4 Sektoren in einen Block <span class="math notranslate nohighlight">\((2^{14} / 2^{12})\)</span> und es gibt im Durchschnitt 64 Blöcke pro Spur <span class="math notranslate nohighlight">\((2^8 / 2^2)\)</span>.</p>
<p>Die Bitdichte für die äußerste Spur wird wie folgt berechnet:</p>
<ul class="simple">
<li><p>Bits pro Spur: <span class="math notranslate nohighlight">\(28 Sektoren x 2^{12} Byte = 2^{20} = 1024 KB = 8 MBit\)</span></p></li>
<li><p>Die Spurlänge (äußerste Spur) beträgt <span class="math notranslate nohighlight">\(3,5“ · p ≈ 11“\)</span></p></li>
<li><p>mit ca. 10% Lücken hat man eine Spurlänge von 9,9“, die 8 MBits hält</p></li>
</ul>
<p>Somit sind 840.000 Bits pro Zoll vorhanden.</p>
</section>
<section id="disk-zugriffseigenschaften">
<h3><span class="section-number">1.2.5. </span>Disk-Zugriffseigenschaften<a class="headerlink" href="#disk-zugriffseigenschaften" title="Permalink to this headline">#</a></h3>
<p>Eine Voraussetzung für den Zugriff auf einen Block (lesend oder schreibend) ist, dass der S-/L-Kopf auf den richtigen Zylinder positioniert ist, der die Spur mit dem Block enthält. Dann muss die Disk so rotieren, dass Sektoren, die der Block enthält, unter den S-/L-Kopf gelangen. </br>
Hierbei sprechen wir von der <strong>Latenzzeit</strong>. Sie beschreibt die Zeit zwischen der Anweisung einen Block zu lesen und bis zum Eintreffen des Blocks im Hauptspeicher.</p>
</section>
<section id="latenzzeit">
<h3><span class="section-number">1.2.6. </span>Latenzzeit<a class="headerlink" href="#latenzzeit" title="Permalink to this headline">#</a></h3>
<p>Die Latenzzeit setzt sich aus der Summe von vier Komponenten zusammen:</p>
<ol class="arabic simple">
<li><p><strong>Kommunikationszeit</strong> zwischen Prozessor und Disk Controller:</p>
<ul class="simple">
<li><p>Sie beträgt nur Bruchteile einer Millisekunde und kann daher bei Berechnungen hier vernachlässigt werden.</p></li>
</ul>
</li>
<li><p><strong>Seektime</strong> (Suchzeit), um den Kopf unter dem richtigen Zylinder zu positionieren:</p>
<ul class="simple">
<li><p>Die Suchzeit ist zwischen 0 und 40 ms ( proportional zum zurückgelegten Weg).</p></li>
<li><p>Sie setzt sich zusammen aus Startzeit (1 ms), Bewegungszeit (0 – 40 ms) und Stopzeit (1 ms).</p></li>
</ul>
</li>
<li><p><strong>Rotationslatenzzeit</strong> für die Drehung der Disk, bis sich der erste Sektor des Blocks unter S-/L-Kopf befindet:</p>
<ul class="simple">
<li><p>Durchschnittlich benötigt es eine halbe Umdrehung (4 ms) bis der erste Sektor des Blocks unter dem S-/L-Kopf liegt.</p></li>
<li><p>Eine Optimierung durch Spur-Cache im Disk-Controller ist möglich.</p></li>
</ul>
</li>
<li><p>Die <strong>Transferzeit</strong> für die Drehung der Disk, bis alle Sektoren und die Lücken des Blocks unter dem S-/L-Kopf durchlaufen sind:</p>
<ul class="simple">
<li><p>Etwa ein 16 KB-Block in 0.25 ms durchlaufen.</p></li>
</ul>
</li>
</ol>
</section>
<section id="schreiben-und-andern-von-blocken">
<h3><span class="section-number">1.2.7. </span>Schreiben und Ändern von Blöcken<a class="headerlink" href="#schreiben-und-andern-von-blocken" title="Permalink to this headline">#</a></h3>
<p>Das Schreiben von Blöcken ist in Bezug zu Vorgehen und Zeit analog zum Lesen. Um zu überprüfen, ob eine Schreiboperation erfolgreich war, muss eine Rotation gewartet werden. (Die Nutzung von Checksums wird später beschrieben). </br></p>
<p>Das <strong>Ändern von Blöcken</strong> ist nicht direkt möglich. Sondern geschieht in 4 Schritten:</p>
<ol class="arabic simple">
<li><p>Der jeweilige Block wird in den Hauptspeicher gelesen.</p></li>
<li><p>Die Daten auf dem Block werden geändert.</p></li>
<li><p>Der Block wird auf die Festplatte zurückgeschrieben.</p></li>
<li><p>Zum Schluss wird eventuell die Korrektheit der Schreiboperation überprüft</p></li>
</ol>
<p>Die Zeit für solch eine Operation ergibt sich aus <span class="math notranslate nohighlight">\(t_{read} + t_{write}\)</span>. Mit ein wenig Glück ist der Kopf noch in der Nähe, wodurch t_write billiger wird.</p>
</section>
<section id="id5">
<h3><span class="section-number">1.2.8. </span>Beispiel – Megatron 747 Disk<a class="headerlink" href="#id5" title="Permalink to this headline">#</a></h3>
<p>Wie lange dauert es, einen Block (16 KB = 16 384 Byte) zu lesen?
Diese Frage soll nun am Beispiel der Megatron 747 Disk beantwortet werden. </br></p>
<p>Die Umdrehungsgeschwindigkeit beträgt <span class="math notranslate nohighlight">\(7200 U · min-1\)</span>. Somit dauert eine Umdrehung 8,33 ms. </br></p>
<p>Zunächst wird die Seektime berechnet: </br>
Die Start- und Stopzeit beträgt zusammen eine Millisekunde. </br>
Pro 4000 Zylinder wird 1ms benötigt:
- Minimal werden 0 Zylinder übersprungen und man bleibt an der Stelle an der man ist. Dafür werden 0ms benötigt.
- Wenn man eine Spur (Track) überspringt, kostet das 1,00025ms (≈1ms).
- Maximal werden 65.536 Zylinder übersprungen und das kostet <span class="math notranslate nohighlight">\(65536/4000 + 1 = 17,38ms\)</span>.
</br></p>
<p>Als nächstes wird die minimale Zeit berechnet, um einen Block zu lesen: </br>
Dafür muss der S-/L-Kopf über der richtigen Spur stehen und die Platte schon richtig rotiert worden sein. Ein Block (16KB) ist über 4 Sektoren und 3 Lücken verteilt. Diese müssen gelesen werden. Insgesamt gibt es durchschnittlich 256 Lücken und 256 Sektoren pro Spur (wurde in vorherigem Unterkapitel so definiert). Die Lücken bedecken 36° (10%) einer Spur. Die Sektoren bedecken 324° des Kreises (360°). </br>
Das Verhältnis wird berechnet mit <span class="math notranslate nohighlight">\(324° x 4 / 256 + 36° x 3 / 256 = 5,48°\)</span>. Es sind also 5,48° des Kreises durch einen Block bedeckt.
5,48° im Verhältnis zur Gesamtrotation (360°) und einer Umdrehung ergeben dann eine Lesezeit von <span class="math notranslate nohighlight">\((5,48° / 360°) · 8,33 ms = 0,13 ms\)</span>.</p>
<p>Die maximale Zeit zum Lesen eines Blocks wird in der Präsenzübung vertieft. (Kleiner Spoiler: Sie beträgt 25,84 ms).
Die durchschnittliche Zeit können Sie selber erforschen und nachrechnen. (Dabei sollten sie auf ungefähr 10,76 ms kommen).</p>
</section>
</section>
<section id="effiziente-diskoperationen">
<h2><span class="section-number">1.3. </span>Effiziente Diskoperationen<a class="headerlink" href="#effiziente-diskoperationen" title="Permalink to this headline">#</a></h2>
<p>Die <strong>Kopfbewegungen</strong> sollen möglichst <strong>minimiert</strong> werden, sodass der Kopf nicht die ganze Zeit von Spur zu Spur oder von Block zu Block hin- und herspringt. Dies zieht gewisse Anforderungen mit sich: Zum Einem sollen die Daten auf der Festplatte sinnvoll liegen. Zum Anderen sollte es Indexstrukturen geben, sodass man nicht Suchen muss.</p>
<section id="algorithmen-vs-dbms">
<h3><span class="section-number">1.3.1. </span>Algorithmen vs. DBMS<a class="headerlink" href="#algorithmen-vs-dbms" title="Permalink to this headline">#</a></h3>
<p>Zuvor war die Annahme bei <strong>Algorithmen</strong> (wie in der Vorlesung ‘Datenstrukturen und Algorithmen’), dass die gesamten Daten in den RAM passen (<strong>RAM-Berechnungsmodell</strong>) und sie auch bereits dort im Hauptspeicher liegen.</p>
<p>Die Annahme bei der Implementierung von <strong>DBMS</strong> ist das <strong>I/O-Modell</strong>. Die gesamten Daten passen nicht mehr in den Hauptspeicher.</p>
<p>Die <strong>Externspeicher-Algorithmen</strong> funktionieren oft anders. Ein guter Externspeicher-Algorithmus muss nicht der beste Algorithmus laut RAM-Modell sein. Sein primäres Entwurfsziel ist es I/O zu vermeiden.</p>
<p>Das Gleiche kann auch für <strong>Hauptspeicher-Algorithmen</strong> gelten. Diese nutzen den <strong>Cache</strong> aus und berücksichtigen die Cachegröße. Es wird versucht die Lokalität zu nutzen und alle fernerliegende Zugriffe zu vermeiden („maximiere“ Anzahl der Cache Hits).</p>
</section>
<section id="i-o-modell">
<h3><span class="section-number">1.3.2. </span>I/O-Modell<a class="headerlink" href="#i-o-modell" title="Permalink to this headline">#</a></h3>
<p>Als Beispiel sei ein einfaches DBMS gegeben. Dieses ist zu groß für den  Hauptspeicher. Es gibt eine Disk, einen Prozessor und viele konkurrierende Nutzer bzw. Anfragen.</p>
<p>Der Disk-Controller hält und organisiert eine <strong>Warteschlange (Priority Queue)</strong> mit Zugriffsaufforderungen auf die Datenbank. Das Abarbeitungsprinzip der Zugriffsaufforderungen ist hierbei first-come-first-served. Generell muss angenommen werden, dass jede Aufforderung zufällig ist. Also der Kopf an einer zufälligen Position ist.</p>
<p>Außerdem dominieren die <strong>I/O-Kosten</strong>. Wir berücksichtigen nicht was im Hauptspeicher geschieht. Die Kosten des Lesens und Bewegens eines Blocks zwischen Disk und Hauptspeicher sind wesentlich größer als die Kosten der Operationen auf den Daten im Hauptspeicher.</p>
<p>Die Anzahl der Blockzugriffe (lesend und schreibend) ist eine gute Approximation der Gesamtkosten und sollte minimiert werden. Anhanddessen kann die Effizienz von Algorithmen beschrieben werden.</p>
</section>
<section id="beispiel-fur-das-i-o-modell-1-indizes">
<h3><span class="section-number">1.3.3. </span>Beispiel für das I/O-Modell (1): Indizes<a class="headerlink" href="#beispiel-fur-das-i-o-modell-1-indizes" title="Permalink to this headline">#</a></h3>
<p>Gegeben sei eine Relation R. Die Anfrage sucht nach dem Tupel t mit dem Schlüsselwert k. </br>
Es existiert ein Index auf dem Schlüsselattribut. Diese Datenstruktur ermöglicht einen schnellen Zugriff auf einen Block, der t enthält. Es gibt zwei Varianten bei Indizes. Die erste Variante gibt nur an in welchem Block t liegt. Die zweite Variante gibt zusätzlich die Stelle von t innerhalb des Blocks an. Die daraus resultierende Frage: Welche Indexvariante ist besser geeignet?</p>
<p>Durchschnittlich benötigt es 11 ms um einen 16 KB-Block zu lesen. In dieser Zeit sind viele Millionen Prozessoranweisungen möglich. Die Suche nach k auf dem Block kostet höchstens Tausende Prozessoranweisungen, selbst mit linearer Suche. Wenn der Block in den Hauptspeicher geladen wurde, sind die Suchkosten darauf verschwindend gering im Vergleich zu den I/O-Kosten. </br>
Die zusätzlichen Informationen (wie der Index zum Beispiel) in Variante B nehmen mehr Platz ein und verursachen höhere I/O-Kosten.</p>
</section>
<section id="beispiel-fur-das-i-o-modell-2-sortierung">
<h3><span class="section-number">1.3.4. </span>Beispiel für das I/O-Modell (2): Sortierung<a class="headerlink" href="#beispiel-fur-das-i-o-modell-2-sortierung" title="Permalink to this headline">#</a></h3>
<p>Es sei eine Relation R mit 10 Millionen Tupeln und verschiedenen Attributen gegeben. Ein Attribut davon ist der Sortierschlüssel, der nicht unbedingt eindeutig ist. Es ist kein Primärschlüssel. In duiesem Beispiel treffen wir die vereinfachende Annahme, dass der Sortierschlüssel eindeutig ist.</p>
<p>Gespeichert werden die Daten auf Diskblöcken der Größe <span class="math notranslate nohighlight">\(16.384 = 2^{14}\)</span> Byte mit der Annahme, dass 100 Tupel in einen Block passen. Damit wäre die Tupelgröße ca. 160 Byte. R belegt dann 100.000 Blöcke (1,64 Mrd. Bytes) auf der Festplatte.</p>
<p>Es wird eine Megatron 747 Festplatte verwendet.
Der verfügbare Hauptspeicherpuffer beträgt <span class="math notranslate nohighlight">\(100 MB (= 100 · 2^{20})\)</span>. Somit passen <span class="math notranslate nohighlight">\((100 * 2^{20}) / (2^{14}) = 6400\)</span> Blöcke von R passen in den Hauptspeicher.</p>
<p>Ziel der Sortierung ist es die Anzahl der Lese- und Schreiboperationen zu minimieren und wenig “Durchläufe” durch die Daten zu haben.</p>
</section>
<section id="merge-sort">
<h3><span class="section-number">1.3.5. </span>Merge Sort<a class="headerlink" href="#merge-sort" title="Permalink to this headline">#</a></h3>
<p>Merge Sort ist ein <strong>Hauptspeicher-Algorithmus</strong> und fällt unter die <strong>Divide-and-Conquer</strong> Algorithmen. Die Idee ist es l ≥ 2 sortierte Listen zu einer größeren sortierten Liste zusammenzumergen. Dazu wählt man aus den sortierten Listen stets das kleinste Element und fügt es der großen Liste hinzu.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>Liste 1</p></th>
<th class="head"><p>Liste 2</p></th>
<th class="head"><p>Outputliste</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1.</p></td>
<td><p>1,3,4,9</p></td>
<td><p>2,5,7,8</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-odd"><td><p>2.</p></td>
<td><p>3,4,9</p></td>
<td><p>2,5,7,8</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even"><td><p>3.</p></td>
<td><p>3,4,9</p></td>
<td><p>5,7,8</p></td>
<td><p>1,2</p></td>
</tr>
<tr class="row-odd"><td><p>4.</p></td>
<td><p>4,9</p></td>
<td><p>5,7,8</p></td>
<td><p>1,2,3</p></td>
</tr>
<tr class="row-even"><td><p>5.</p></td>
<td><p>9</p></td>
<td><p>5,7,8</p></td>
<td><p>1,2,3,4</p></td>
</tr>
<tr class="row-odd"><td><p>6.</p></td>
<td><p>9</p></td>
<td><p>7,8</p></td>
<td><p>1,2,3,4,5</p></td>
</tr>
<tr class="row-even"><td><p>7.</p></td>
<td><p>9</p></td>
<td><p>8</p></td>
<td><p>1,2,3,4,5,7</p></td>
</tr>
<tr class="row-odd"><td><p>8.</p></td>
<td><p>9</p></td>
<td><p>-</p></td>
<td><p>1,2,3,4,5,7,8</p></td>
</tr>
<tr class="row-even"><td><p>9.</p></td>
<td><p>-</p></td>
<td><p>-</p></td>
<td><p>1,2,3,4,5,7,8,9</p></td>
</tr>
</tbody>
</table>
<p>Die <strong>Rekursion</strong> bei Merge Sort beginnt mit dem beliebigen Aufteilen einer Liste mit mehr als einem Element in zwei gleich lange Listen L1 und L2.
Die Teillisten L1 und L2 werden rekursiv <strong>sortiert</strong>. Danach werden beide Teillisten zu einer sortierten Liste <strong>gemerged</strong>. </br>
</br>
Der <strong>Aufwand</strong> von Merge Sort lässt sich in ein paar Schritten berechnen. Die Eingabegröße ist |R| = n. </br>
Das Mergen zweier sortierter Listen L1, L2 kostet: O(|L1| + |L2|) = O(n). </br>
Die Rekursionstiefe ist log2(n), da sich in jedem Rekursionsschritt die Listenlänge halbiert. Nach i Schritten sind noch n / 2^i Elemente in der Liste.
</br>
Ergo ergibt sich ein Aufwand von O(n log n). Das trifft die untere Schranke für das vergleichsbasierte Sortieren.</p>
</section>
<section id="two-phase-multiway-merge-sort-tpmms">
<h3><span class="section-number">1.3.6. </span>Two-Phase, Multiway Merge-Sort (TPMMS)<a class="headerlink" href="#two-phase-multiway-merge-sort-tpmms" title="Permalink to this headline">#</a></h3>
<p>TPMMS wird in vielen DBMS eingesetzt. Es besteht aus zwei Phasen:</p>
<p><strong>Phase 1</strong> </br>
In der ersten Phase werden jeweils so viele Tupel geladen wie in den Hauptspeicher passen. Die Teilstücke werden im Hauptspeicher sortiert und auf die Festplatte zurückgeschrieben. Das Ergebnis sind viele sortierte Teillisten auf der Festplatte.</p>
<p><strong>Phase 2</strong> </br>
In der Phase werden alle sortierten Teillisten zu einer einzigen großen Liste gemerged.</p>
</section>
<section id="tpmms-phase-1">
<h3><span class="section-number">1.3.7. </span>TPMMS - Phase 1<a class="headerlink" href="#tpmms-phase-1" title="Permalink to this headline">#</a></h3>
<p>Der Rekursionsanfang ist nun nicht nur mit einem oder zwei Elementen! Die Sortierung der Teillisten erfolgt bei TPMMS z.B. mit Quicksort, welches im worst-case sehr selten ein Aufwand von O(n^2) hat. </br>
</br>
Der <strong>Ablauf</strong> der ersten Phase hat drei Schritte:</p>
<ol class="arabic simple">
<li><p>Zunächst wird der verfügbare Hauptspeicher mit Diskblöcken aus der Originalrelation gefüllt</p></li>
<li><p>Die Tupel, die sich im Hauptspeicher befinden, werden sortiert.</p></li>
<li><p>Die sortierten Tupel werden auf die neuen Blöcke der Disk geschrieben. Das Ergebnis ist eine sortierte Teilliste.</p></li>
</ol>
<p>Ein <strong>Beispiel</strong> dazu: Seien 6,400 Blöcke im Hauptspeicher; also insgesamt 100,000 Blöcke. Es sind 16 Füllungen des Hauptspeichers erforderlich. Die letzte Füllung ist kleiner. </br>
Ein Aufwand von 200,000 I/O-Operationen ergibt sich, da 100,000 Blöcke gelesen und 100,000 Blöcke geschreiben werden.</p>
<p>Für eine I/O-Operation wird durchschnittlich eine Zeit von 11 ms benötigt.
Insgesamt ergben sich <span class="math notranslate nohighlight">\(11 ms * 200,000 = 2,200 s = 37 min\)</span>. Die Prozessorzeit für das Sortieren ist dabei vernachlässigbar.</p>
</section>
<section id="tpmms-phase-2">
<h3><span class="section-number">1.3.8. </span>TPMMS - Phase 2<a class="headerlink" href="#tpmms-phase-2" title="Permalink to this headline">#</a></h3>
<p>Die naive Idee von Phase 2 ist das paarweise Mergen von k sortierten Teillisten. Man muss <span class="math notranslate nohighlight">\(2 * log2(k)\)</span> jeden Block (jedes Tupels) Lesen und Schreiben.</p>
<p>Im <strong>Beispiel</strong>: Ein Durchlauf für 16 sortierte Teillisten, einer für 8, einer für 4 und ein letzter für 2 sortierte Teillisten. Insgesamt ist jeder Block an 8 I/O-Operationen beteiligt. Es wird deutlich mehr Zeit benötigt. Eine bessere Idee wäre es nur den ersten Block jeder Teilliste zu lesen:</p>
<ol class="arabic simple">
<li><p>Suche den kleinsten Schlüssel unter den ersten Tupeln aller Blöcke (Lineare Suche (lin.), Priority Queue (log.)).</p></li>
<li><p>Bewege dieses Element in den Output-Block (im Hauptspeicher).</p></li>
<li><p>Falls der Output-Block voll ist, schreibe ihn auf die Festplatte.</p></li>
<li><p>Falls ein Input-Block leer ist, lese den nächsten Block aus derselben Liste. Der Aufwand beträgt 2 I/O-Operationen pro Block (und Tupel). Dies dauert ebenfalls 37 Minuten.</p></li>
</ol>
<p>Die Laufzeit für TPMMS insgesamt beträgt somit 74 Minuten.</p>
</section>
<section id="bemerkungen-zur-blockgrosze">
<h3><span class="section-number">1.3.9. </span>Bemerkungen zur Blockgröße<a class="headerlink" href="#bemerkungen-zur-blockgrosze" title="Permalink to this headline">#</a></h3>
<p>Es lässt sich beobachten, dass je größer die Blockgröße ist, desto weniger I/O-Operationen werden benötigt. Die Transferzeit erhöht sich dabei etwas.</p>
<p>Das <strong>bisherige Beispiel</strong>:</p>
<ul class="simple">
<li><p>Blockgröße: 16 KB</p></li>
<li><p>∅ Latenzzeit: 10,88 ms (davon nur 0,253 ms für Transfer)</p></li>
</ul>
<p>Das <strong>neue Beispiel</strong> mit erhöhter Blockgröße:</p>
<ul class="simple">
<li><p>Blockgröße: 512 KB (16 * 32)</p></li>
<li><p>∅ Latenzzeit: 20 ms (davon 8 ms für Transfer)</p></li>
</ul>
<p>Es werden nur noch 12.500 I/O-Operationen für die Sortierung benötigt. Die Gesamtzeit beträgt 4,16 Minuten. Es ergibt sich eine 17-fache Beschleunigung!</p>
</br>
Die **Nachteile** der Blockvergrößerung:
    - Blocks sollten sich nicht über mehrere Spuren erstrecken.
    - Kleine Relationen nutzen nur Bruchteile eines Blocks, was zu Speicherverschwendung führt.
    - Viele Datenstrukturen für Externspeicher bevorzugen die Aufteilung von Daten auf viele kleine Blöcke.</section>
<section id="tpmms-grenzen">
<h3><span class="section-number">1.3.10. </span>TPMMS – Grenzen<a class="headerlink" href="#tpmms-grenzen" title="Permalink to this headline">#</a></h3>
<p>Vorweg ein paar Stichpunkte zur <strong>Notation</strong>:</p>
<ul class="simple">
<li><p>Blockgröße: B Bytes</p></li>
<li><p>Hauptspeichergröße (für Blocks): M Bytes</p></li>
<li><p>Tupelgröße: R Bytes
</br></p></li>
</ul>
<p><strong>Grenzen</strong>:</p>
<ul class="simple">
<li><p>Man kann somit sagen, dass <span class="math notranslate nohighlight">\(M / B\)</span> Blöcke in den Hauptspeicher passen.</p></li>
<li><p>In Phase 2 wird außerdem Platz für einen Outputblock benötigt.</p></li>
<li><p>Phase 1 kann also genau <span class="math notranslate nohighlight">\((M / B) - 1\)</span> sortierte Teillisten erzeugen. Ebenso oft kann der Hauptspeicher mit Tupeln gefüllt und sortiert werden (in Phase 1). Jede Füllung enthält <span class="math notranslate nohighlight">\(M / R Tupel\)</span>.</p></li>
<li><p>Maximal können <span class="math notranslate nohighlight">\((\frac{M}{R}) \cdot ((\frac{M}{B}) - 1)\)</span> Tupel sortiert werden. </br>
</br></p></li>
<li><p>In dem Beispiel:</p>
<ul>
<li><p>M = 104,857,600 Bytes</p></li>
<li><p>B = 16,384 Bytes</p></li>
<li><p>R = 160 Bytes</p></li>
<li><p>Zusammen ergibt sich eine maximale Eingabegröße von 4.2 Milliarden Tupeln (ca. 0.67 Terabyte)</p></li>
</ul>
</li>
</ul>
<figure class="align-default" id="tpmms-grenzen-visualisierung">
<img alt="../_images/TPMMS-Grenzen-Visualisierung.png" src="../_images/TPMMS-Grenzen-Visualisierung.png" />
<figcaption>
<p><span class="caption-number">Fig. 1.21 </span><span class="caption-text">TPMMS Grenzen Visualisierung</span><a class="headerlink" href="#tpmms-grenzen-visualisierung" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Falls die Eingaberelation noch größer ist, wird eine dritte Phase hinzugefügt. TPMMS wird genutzt, um sortierte Listen der Größe <span class="math notranslate nohighlight">\(M^2/RB\)</span> zu erzeugen. In der dritten Phase wird maximal <span class="math notranslate nohighlight">\(M/B - 1\)</span> solcher Listen zu einer sortierten Liste zusammengemerged. Insgesamt sind <span class="math notranslate nohighlight">\(M^3/RB^2\)</span> Tupel sortierbar. Bezogen auf unser Beispiel, gibt es nun eine maximale Eingabegröße von 27 Billionen Tupeln (ca. 4.3 Petabytes). Global betrachtet ist die zweite Phase die zusätzliche Phase.</p>
</section>
</section>
<section id="zugriffsbeschleunigung">
<h2><span class="section-number">1.4. </span>Zugriffsbeschleunigung<a class="headerlink" href="#zugriffsbeschleunigung" title="Permalink to this headline">#</a></h2>
<p>Bisher waren die Annahmen, dass es nur eine Disk gibt und die Blockzugriffe (viele kleine Anfragen) zufällig geschehen.
Dafür gibt es verschiedene Verbesserungsideen:</p>
<ul class="simple">
<li><p>Blöcke, die gemeinsam gelesen werden, werden auf dem gleichen <strong>Zylinder</strong> platziert, um die Suchzeit zu reduzieren.</p></li>
<li><p>Die Daten werden auf mehrere (kleine) Disks verteilt (<strong>Verteilung</strong>), sodass man unabhängige Schreib-/Leseköpfe hat, die es ermöglichen mehrere (unabhängige) Blockzugriffe gleichzeitig durchzuführen.</p></li>
<li><p><strong>Spiegelung</strong> von Daten auf mehrere Disks.</p></li>
<li><p>Verwendung eines Disk-<strong>Scheduling</strong>-Algorithmus.</p></li>
<li><p><strong>Prefetching</strong> von Blöcken: Das Ablegen von Blöcken im Hauptspeicher, die möglicherweise demnächst benötigt werden.</p></li>
</ul>
<section id="daten-gemasz-zylinder-organisieren">
<h3><span class="section-number">1.4.1. </span>Daten gemäß Zylinder organisieren<a class="headerlink" href="#daten-gemasz-zylinder-organisieren" title="Permalink to this headline">#</a></h3>
<p>Die Seektime macht ca. 50% der durchschnittlichen Blockzugriffszeit aus.
Beim Megatron 747 beträgt die Seektime zwischen 0 und 40 ms.
Die Idee dabei ist es die Daten, die zusammen gelesen werden, auf dem gleichen Zylinder zu platzieren. Zum Beispiel die Tupel einer Relation. Falls ein Zylinder nicht ausreicht, werden mehrere nebeneinander liegende Zylinder genutzt. Beim Lesen einer Relation fällt im besten Fall nur einmal die Seektime und Rotationslatenz an. Es wird nun die minimale Zugriffszeit der Disk erreicht: Die Zugriffszeit wird nur noch durch die Transferzeit bestimmt. </br>
Ein Zylinder der Megatron 747 fasst 16 x 64 = 1024 Blöcke. Dennoch sind dann 16 Umdrehungen erforderlich (+ 15x seek über je eine Spur).</p>
</section>
<section id="zylinderorganisation-beispiel">
<h3><span class="section-number">1.4.2. </span>Zylinderorganisation - Beispiel<a class="headerlink" href="#zylinderorganisation-beispiel" title="Permalink to this headline">#</a></h3>
<p>Ein paar Daten zur Megatron 747-Festplatte:</p>
<ul class="simple">
<li><p>Mittlere Transferzeit pro Block: ¼ ms.</p></li>
<li><p>Mittlere seek time: 6,46 ms</p></li>
<li><p>Mittlere Rotationslatenzzeit: 4,17 ms</p></li>
<li><p>16 Oberflächen mit 65.536 Spuren á 64 Blöcke (durchschnittlich)</p></li>
</ul>
<p>Die Sortierung von 10 Mio. Tupeln mittels des TPMMS-Algorithmus dauerte 74 min. 100.000 Blöcke von R belegen 1563 Spuren (98 Zylinder).
</br></br>
Im ersten Teil der <strong>Phase 1</strong> kommt es zum <strong>Lesen</strong> der Blöcke. Dazu wird der Hauptspeicher (mit 6400 Blöcke) 16 mal gefüllt. Es müssen die Blöcke von 6400/1024 = 6-7 Zylindern gelesen werden, die aber direkt nebeneinander liegen. Der Spurwechsel kostet nur 1ms. Die Reihenfolge beim Lesen der Tupel ist egal, wodurch man sich Rotationslatenzzeit spart. Die Zeit pro Füllung ergibt sich durch:
- 6,46 ms + 6 ms + 6x8ms + 1,6s ≈ 1,6 s
- Also: (1.seek) + (ca. 6 Spurwechsel) + (6 Rotationen) + (Transfer 6400 Blöcke)
- Insgesamt: 1,6s x 16 Füllungen = 26s (&lt;&lt;18min)
</br></br>
Im zweiten Teil der <strong>Phase 1</strong> kommt es zum <strong>Schreiben</strong>: analog zum Lesen ergibt sich beim Schreiben zusammen 52s. Vorher waren es 37 min. Achtung dabei: Die Rotationslatenz ist hier eigentlich wieder relevant…
</br></br>
<strong>Phase 2</strong> wird nicht beschleunigt. Es wird aus verschiedenen (verteilten) Teillisten gelesen. Das Schreiben des Ausgabepuffers ist zwar sequentiell, wird aber von Leseoperationen unterbrochen.</p>
</section>
<section id="mehrere-disks">
<h3><span class="section-number">1.4.3. </span>Mehrere Disks<a class="headerlink" href="#mehrere-disks" title="Permalink to this headline">#</a></h3>
<p>Bei der Nutzung von einer Disk gibt es das Problem, dass sich die S-/L-Köpfe einer Festplatte stets gemeinsam bewegen. Als Lösung des Problems kann man mehrere Festplatten (mit unabhängigen Köpfen) nutzen unter der Annahme, dass Disk-Controller, Hauptspeicher und Bus mit höheren Transferraten klarkommen. Das Resultat aus der Nutzung mehrerer Festplatten ist die Division aller Zugriffszeiten durch die Festplattenanzahl.</br>
Eine Megatron 737 hat im Gegensatz zur Megatron 747 nur 2 Platten (also 4 Plattenoberflächen). Im Vergleich dazu hat die Megatron 747 8 Platten (also 16 Plattenoberflächen). Dementsprechend soll nun eine Megatron 747 durch vier Megatron 737 ersetzt werden, um die Zugriffszeiten zu minimieren. R wird somit auf 4 Festplatten verteilt.
</br></br>
<strong>TPMMS - Phase 1</strong></br></p>
<p>Von jeder Platte müssen nun nur ¼ der Daten (1600 Blöcke) gelesen (<strong>Lesen</strong>) werden. Durch die günstige Zylinderorganisation ist die Seektime und Rotationslatenz ungefähr 0. Die Transferzeit benötigt 600 Blöcke × 0,25 ms (mittlere Transferzeit)= 400 ms pro Füllung. Bei 16 Füllungen und 400 ms pro Füllung dauert dies insgesamt: 16 Füllungen x 400 ms = 6,4 s.
</br></p>
<p>Beim <strong>Schreiben</strong> wird jede Teilliste auf 4 Disks verteilt. Dies benötigit so viel Zeit wie beim Lesen: 6,4 s. Zusammen also ungefähr 13s statt 52s zuvor bzw. 37 min bei zufälliger Anordnung.
</br></br></p>
<p><strong>TPMMS - Phase 2</strong>
</br>
In der zweiten Phase nützt die Verteilung auf 4 Disks zunächst nichts. Immer wenn ein Block einer Teilliste abgearbeitet ist, wird ein nächster Block dieser Teilliste in den Hauptspeicher geladen. Erst wenn der nächste Block vollständig geladen ist, kann das Mergen fortgesetzt werden. </br>
Der Trick beim Lesen ist es, dass das Mergen fortgesetzt werden kann bevor der Block vollständig in den Hauptspeicher geladen wurde. Das erste Element genügt schon. So können potenziell mehrere Blöcke parallel (jeweils einer pro Teilliste) geladen werden. Dabei kommt es zu einer Verbesserung, sofern diese auf unterschiedlichen Festplatten sind. Man sollte Vorsicht walten lassen, da es eine sehr delikate Implementierung ist. Damit befassen sich unter Anderem Datenbank- oder auch Systemingenieure. </br>
Beim Schreiben des Outputs werden mehrere Output-Blöcke (hier: 4) verwendet. Einer wird gefüllt während die anderen drei geschrieben werden oder parallel, wenn auf unterschiedliche Festplatten geschrieben wird. </br>
Die geschätzte Beschleunigung von Phase 2 beträgt einen Faktor von 2 bis 3.</p>
</section>
<section id="disk-scheduling">
<h3><span class="section-number">1.4.4. </span>Disk Scheduling<a class="headerlink" href="#disk-scheduling" title="Permalink to this headline">#</a></h3>
<p>Beim Disk Scheduling soll der Disk-Controller entscheiden, welche Zugriffsanweisungen zuerst ausgeführt werden. Das ist nützlich bei vielen kleinen Prozessen auf je wenigen Blöcken. Häufig somit der Fall bei <a class="reference external" href="https://www.oracle.com/de/database/what-is-oltp/">OLTP</a> (Online Transaction Processing). Dabei ist die Erhöhung des Durchsatzes das Ziel.
</br>
<strong>Elevator Algorithmus</strong>
Die Idee des Algorithmus kommt von Fahrstühlen. Ein Fahrstuhl fährt in einem Gebäude hoch und runter und hält an Stockwerken an, wenn jemand ein- oder aussteigen will. Er dreht um, falls weiter oben/unten keiner mehr wartet.</br>
Analog dazu streicht ein Diskkopf über die Oberfläche einwärts und auswärts und hält an Zylindern an, wenn es eine (oder mehrere) Zugriffsanweisung(en) gibt. Er dreht um, falls in der jeweiligen Richtung keine Anweisungen mehr ausstehen.</p>
</section>
<section id="spiegelung">
<h3><span class="section-number">1.4.5. </span>Spiegelung<a class="headerlink" href="#spiegelung" title="Permalink to this headline">#</a></h3>
<p>Die Idee der Spiegelung ist es, dass zwei oder mehr Festplatten <strong>identische Kopien</strong> halten. Dadurch entsteht mehr Sicherheit vor Datenverlust und man hat einen beschleunigten Lesezugriff. Bei n Festplatten kann es bis zu n mal so schnell sein. </br>
Beim Lesen in der 2. Phase von TPMMS klappt der Trick wie bei mehreren Disks nicht immer. Es gibt keine Verbesserung, falls Blöcke verschiedener Teillisten auf der gleichen Festplatte liegen. Bei einer Spiegelung kann garantiert werden, dass immer so viele Blöcke unterschiedlicher Teillisten parallel gefüllt werden, wie Spiegelungen vorhanden sind.</br>
Ein weiterer Vorteil, auch ohne Parallelität bei weniger als n Blöcke gleichzeitig: Es ist möglich die Festplatte auszuwählen, auf die zugegriffen wird. Man sollte die Festplatte wählen, deren Kopf am dichtesten an der relevanten Spur steht.
</br>
Ein paar weitere Anmerkungen zu Spiegelungen: Sie sind teuer und verursachen keine Beschleunigung des Schreibzugriffs, aber auch keine Verlangsamung.</p>
</section>
<section id="first-come-first-serve-vs-elevator-algorithmus">
<h3><span class="section-number">1.4.6. </span>First-Come-First-Serve vs. Elevator Algorithmus<a class="headerlink" href="#first-come-first-serve-vs-elevator-algorithmus" title="Permalink to this headline">#</a></h3>
<figure class="align-default" id="fcfs-vs-elevator-algo">
<img alt="../_images/FCFS-vs-Elevator-Algo.png" src="../_images/FCFS-vs-Elevator-Algo.png" />
<figcaption>
<p><span class="caption-number">Fig. 1.22 </span><span class="caption-text">FCFS vs. Elevator-Algorithmus</span><a class="headerlink" href="#fcfs-vs-elevator-algo" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Das kleine Beispiel zeigt den Vergleich zwischen First Come First Serve (kurz FCFS) und dem Elevator Algorithmus. Der Elevator-Algorithmus ist hierbei mit 57,52 nur etwas schneller als FCFS mit 71,52. In größeren Beispielen ist der Unterschied ausgeprägter.</p>
</section>
<section id="elevator-algorithmus">
<h3><span class="section-number">1.4.7. </span>Elevator Algorithmus<a class="headerlink" href="#elevator-algorithmus" title="Permalink to this headline">#</a></h3>
<p>Die Verbesserung durch den Elevator Algorithmus steigt mit durchschnittlicher Anzahl von wartenden Anweisungen. Bei so vielen wartenden Zugriffsanweisungen wie die Anzahl an Zylindern geht jeder Seek nur über wenige Zylinder. Die durchschnittliche Seektime (bezogen auf die wartenden Zugriffsanweisungen) wird verringert. </br>
Grundsätzlich gibt es weniger Zylinder als es Zugriffsanweisungen gibt. Es gibt mehrere Zugriffsanweisungen pro Zylinder, die gleichzeitig verarbeitet werden können. Man kann zudem noch die Anweisungen sinnvoll sortieren, sodass man die Blöcke in sinnvoller Reihenfolge von den Zylindern liest. Dadurch reduziert sich die Rotationslatenzzeit.</br>
Zu einem Nachteil kommt es, falls die Anzahl wartender Anweisungen zu groß ist. Die Wartezeiten für einzelne Zugriffsanweisungen werden dann sehr groß!</p>
</section>
<section id="prefetching">
<h3><span class="section-number">1.4.8. </span>Prefetching<a class="headerlink" href="#prefetching" title="Permalink to this headline">#</a></h3>
<p>Die Idee von Prefetching ist es, voraussagen zu können, welche Blöcke in naher Zukunft gebraucht werden. Diese kann man dann früh (bzw. während man sie sowieso passiert) in den Hauptspeicher laden.</br>
Beim Lesen in der 2. Phase von TPMMS werden 16 Blöcke für die 16 Teillisten reserviert. Es ist viel Hauptspeicher frei. Daher können zwei Blöcke pro Teilliste reserviert werden. Man geht bei TPMMS sowieso davon aus, dass der nächste Block irgendwann gelesen wird. Ein Block wird dann gefüllt, während der andere abgearbeitet wird. Wenn einer entleert ist, wird zum Anderen gewechselt. Die Laufzeit wird aber nicht verbessert.</br>
Daher als Idee zur Verbesserung: Die Kombination mit guter Spur- oder Zylinderorganisation.
Beim Schreiben in Phase 1 von TPMMS sollen Teillisten auf ganze, aufeinanderfolgende Spuren / Zylinder geschrieben werden.
Beim Lesen in Phase 2 von TPMMS sollen ganze Spuren / Zylinder gelesen werden, wenn aus einer Liste ein neuer Block benötigt wird. </br>
Die Idee für das Schreiben ist analog. Nicht jeder Block, der fertig ist, soll direkt auf die Disk geschrieben werden. Die Schreiboperationen sollen hinausgezögert werden bis die ganze Spur / der ganze Zylinder geschrieben werden kann. Außerdem sollen mehrere Ausgabepuffer verwendet werden. Während einer auf die Festplatte geleert wird, wird in den Anderen geschrieben.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "LUH-DBS/GDBS_Script",
            ref: "main/",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./01"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Datenbanksysteme II</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../02/repraesentation.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">2. </span>Repräsentation</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Prof. Dr. Ziawasch Abedjan<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>